{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import traceback\n",
    "import datetime\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pyzipcode\n",
    "import hashlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import statsmodels.stats.multitest as multitest\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "import sklearn.preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, LeaveOneOut, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import functools\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews = pd.read_pickle(\"../data/pickles/yelpchi_reviews.pkl\")\n",
    "yc_updated_reviews = pd.read_pickle(\"../data/pickles/yelpchi_updated_reviews.pkl\")\n",
    "yc_businesses = pd.read_pickle(\"../data/pickles/yelpchi_businesses_with_chain.pkl\")\n",
    "\n",
    "chicago_reviews = pd.read_pickle(\"../data/pickles/chicago_reviews.pkl\")\n",
    "chicago_businesses = pd.read_pickle(\"../data/pickles/chicago_businesses.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_yc = yc_reviews.date.max()\n",
    "yc_new_reviews = yc_updated_reviews[yc_updated_reviews.date > max_yc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews.rating.groupby(by=yc_reviews.rating).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variational_distance(sample_a, sample_b):\n",
    "    \"\"\"\n",
    "    Based on the L1 distance here: https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures\n",
    "    \n",
    "    TODO switch to log probabilities if needed\n",
    "    \"\"\"\n",
    "    sample_a = pd.Series(sample_a)\n",
    "    sample_b = pd.Series(sample_b)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"a\"] = sample_a.groupby(sample_a).size()\n",
    "    df[\"b\"] = sample_b.groupby(sample_b).size()\n",
    "    df = df.fillna(0)\n",
    "    df[\"a\"] = df.a / sum(df.a)\n",
    "    df[\"b\"] = df.b / sum(df.b)\n",
    "\n",
    "    s = 0\n",
    "    l1 = np.abs(np.array(df.a)-np.array(df.b))\n",
    "    tvd = np.sum(l1) * 0.5\n",
    "    return tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variational_distance(yc_reviews.rating,yc_updated_reviews.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the ratio of filtered:total reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_ratio(bid):\n",
    "    #print(bid)\n",
    "    business_reviews = yc_updated_reviews[(yc_updated_reviews.businessID == bid)]\n",
    "    business_filtered_reviews = business_reviews[business_reviews.flagged == 'Y']\n",
    "    \n",
    "    return len(business_filtered_reviews) / len(business_reviews)\n",
    "    \n",
    "yc_businesses[\"filtered_ratio\"] = pd.Series(yc_businesses.index, index=yc_businesses.index).apply(get_filtered_ratio)\n",
    "\n",
    "def get_filtered_ratio(bid):\n",
    "    business_reviews = yc_reviews[(yc_reviews.businessID == bid)]\n",
    "    business_filtered_reviews = business_reviews[business_reviews.flagged == 'Y']\n",
    "    \n",
    "    return len(business_filtered_reviews) / len(business_reviews)\n",
    "    \n",
    "yc_businesses[\"yc_filtered_ratio\"] = pd.Series(yc_businesses.index, index=yc_businesses.index).apply(get_filtered_ratio)\n",
    "\n",
    "def get_filtered_ratio(bid):\n",
    "    business_reviews = yc_new_reviews[(yc_new_reviews.businessID == bid)]\n",
    "    business_filtered_reviews = business_reviews[business_reviews.flagged == 'Y']\n",
    "    \n",
    "    if len(business_reviews) == 0:\n",
    "        return None\n",
    "    \n",
    "    return len(business_filtered_reviews) / len(business_reviews)\n",
    "    \n",
    "yc_businesses[\"yc_new_filtered_ratio\"] = pd.Series(yc_businesses.index, index=yc_businesses.index).apply(get_filtered_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yc_updated_reviews[yc_updated_reviews.businessID == \"tQfLGoolUMu2J0igcWcoZg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_businesses.sort_values(\"filtered_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratings stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.75,5.5,0.5)\n",
    "sns.distplot(yc_businesses.rating,bins=bins,kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the divergence between the rating distribution overall and for each businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.75,5.5,0.5)\n",
    "sns.distplot(yc_updated_reviews.rating,kde=False,bins=bins)\n",
    "sns.distplot(yc_updated_reviews[yc_updated_reviews.flagged=='N'].rating,kde=False,bins=bins)\n",
    "sns.distplot(yc_updated_reviews[yc_updated_reviews.flagged=='Y'].rating,kde=False,bins=bins)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.epps_singleton_2samp(yc_updated_reviews[yc_updated_reviews.flagged=='N'].rating,yc_updated_reviews[yc_updated_reviews.flagged=='Y'].rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_baseline_trunc = sorted(yc_updated_reviews[yc_updated_reviews.flagged=='N'].rating)\n",
    "ratings_baseline_mixed = sorted(yc_updated_reviews.rating)\n",
    "ratings_baseline_filtd = sorted(yc_updated_reviews[yc_updated_reviews.flagged=='Y'].rating)\n",
    "\n",
    "yc_ratings_baseline_trunc = sorted(yc_reviews[yc_reviews.flagged=='N'].rating)\n",
    "yc_ratings_baseline_mixed = sorted(yc_reviews.rating)\n",
    "yc_ratings_baseline_filtd = sorted(yc_reviews[yc_reviews.flagged=='Y'].rating)\n",
    "\n",
    "yc_new_ratings_baseline_trunc = sorted(yc_new_reviews[yc_new_reviews.flagged=='N'].rating)\n",
    "yc_new_ratings_baseline_mixed = sorted(yc_new_reviews.rating)\n",
    "yc_new_ratings_baseline_filtd = sorted(yc_new_reviews[yc_new_reviews.flagged=='Y'].rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_trunc = pd.DataFrame()\n",
    "distance_mixed = pd.DataFrame()\n",
    "distance_filtd = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics to use\n",
    "\n",
    "def get_tvd(baseline,comparison):\n",
    "    if len(comparison) < 5:\n",
    "        return None\n",
    "    return pd.Series([total_variational_distance(baseline,comparison)],index=[\"statistic\"])\n",
    "\n",
    "def get_es2(baseline,comparison):\n",
    "    if len(comparison) < 5:\n",
    "        return None\n",
    "    return pd.Series(scipy.stats.epps_singleton_2samp(baseline,comparison),index=[\"statistic\",\"pvalue\"])\n",
    "\n",
    "def get_ks2(baseline,comparison):\n",
    "    if len(comparison) < 5:\n",
    "        return None\n",
    "    return pd.Series(scipy.stats.ks_2samp(baseline,comparison),index=[\"statistic\",\"pvalue\"])\n",
    "\n",
    "def metric_wrapper(metric_fxn=None,df_baseline=None,mode=None):\n",
    "    \"\"\"\n",
    "    Mode: N - flagged N; Y - flagged Y; A - any flag\n",
    "    \"\"\"\n",
    "    def wrapped(group):\n",
    "        if mode == \"Y\":\n",
    "            return metric_fxn(df_baseline,group[group.flagged=='Y'].rating)\n",
    "        elif mode == \"N\":\n",
    "            return metric_fxn(df_baseline,group[group.flagged=='N'].rating)\n",
    "        elif mode == \"A\":\n",
    "            return metric_fxn(df_baseline,group.rating)\n",
    "        else:\n",
    "            raise\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_metric(metric_fxn=None,metric_name=None,log=False,pvalue=False,df=None,df_name=None,df_baseline=None,mode=None):\n",
    "    \n",
    "    if len(df_name) > 0:\n",
    "        df_name = f\"{df_name}_\"\n",
    "    \n",
    "    distance_addition = pd.DataFrame()\n",
    "    \n",
    "    #Wrap function\n",
    "    metric_fxn = metric_wrapper(metric_fxn, df_baseline, mode)\n",
    "\n",
    "    #Compute statistic\n",
    "    distance_results = df.groupby(\"businessID\").apply(metric_fxn)\n",
    "\n",
    "    #Adjust the p-values to account for multiple hypothesis testing\n",
    "    if pvalue:\n",
    "        results = multitest.multipletests(distance_results[distance_results.pvalue.notnull()][\"pvalue\"])\n",
    "        distance_addition[f\"{df_name}{metric_name}_pvalue\"] = pd.Series(results[1],index=distance_results[distance_results.pvalue.notnull()].index)\n",
    "        distance_addition[f\"{df_name}{metric_name}_significant\"] = pd.Series(results[0],index=distance_results[distance_results.pvalue.notnull()].index)\n",
    "\n",
    "    #Rename\n",
    "    distance_addition[f\"{df_name}{metric_name}_statistic\"] = distance_results[\"statistic\"]\n",
    "\n",
    "    if log:\n",
    "        distance_addition[f\"{df_name}log_{metric_name}_statistic\"] = np.log(distance_addition[f\"{df_name}{metric_name}_statistic\"])\n",
    "        \n",
    "    return distance_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_args(metric_name):\n",
    "    metric_args = {\n",
    "        \"tvd\": {\n",
    "            \"metric_fxn\": get_tvd,\n",
    "            \"log\": False,\n",
    "            \"pvalue\": False\n",
    "        },\n",
    "        \"es\": {\n",
    "            \"metric_fxn\": get_es2,\n",
    "            \"log\": True,\n",
    "            \"pvalue\": True\n",
    "        },\n",
    "        \"ks\": {\n",
    "            \"metric_fxn\": get_ks2,\n",
    "            \"log\": False,\n",
    "            \"pvalue\": True\n",
    "        }\n",
    "    }[metric_name]\n",
    "    \n",
    "    metric_args[\"metric_name\"] = metric_name\n",
    "    \n",
    "    return metric_args\n",
    "\n",
    "def get_df_args(df_name,mode):\n",
    "    df_args = {\n",
    "        \"\": {\n",
    "            \"df\": yc_updated_reviews\n",
    "        },\n",
    "        \"yc\": {\n",
    "            \"df\": yc_reviews\n",
    "        },\n",
    "        \"yc_new\": {\n",
    "            \"df\": yc_new_reviews\n",
    "        }\n",
    "    }[df_name]\n",
    "    df_args[\"df_name\"] = df_name\n",
    "    \n",
    "    df_baseline = {\n",
    "        \"\": {\n",
    "            \"A\": ratings_baseline_mixed,\n",
    "            \"Y\": ratings_baseline_filtd,\n",
    "            \"N\": ratings_baseline_trunc\n",
    "        },\n",
    "        \"yc\": {\n",
    "            \"A\": yc_ratings_baseline_mixed,\n",
    "            \"Y\": yc_ratings_baseline_filtd,\n",
    "            \"N\": yc_ratings_baseline_trunc\n",
    "        },\n",
    "        \"yc_new\": {\n",
    "            \"A\": yc_new_ratings_baseline_mixed,\n",
    "            \"Y\": yc_new_ratings_baseline_filtd,\n",
    "            \"N\": yc_new_ratings_baseline_trunc,\n",
    "        }\n",
    "    }[df_name][mode]\n",
    "\n",
    "    mode_args = {\n",
    "        \"df_baseline\": df_baseline,\n",
    "        \"mode\": mode\n",
    "    }\n",
    "    \n",
    "    df_args.update(mode_args)\n",
    "    return df_args\n",
    "\n",
    "def get_args(metric_name=None,df_name=None,mode=None):\n",
    "    args = get_metric_args(metric_name)\n",
    "    args.update(get_df_args(df_name,mode))\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_trunc = pd.DataFrame()\n",
    "distance_mixed = pd.DataFrame()\n",
    "distance_filtd = pd.DataFrame()\n",
    "for metric_name in [\"tvd\",\"ks\",\"es\"]:\n",
    "    for df_name in [\"\",\"yc\",\"yc_new\"]:\n",
    "        distance_trunc_addition = update_with_metric(**get_args(metric_name,df_name,\"N\"))\n",
    "        distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "    \n",
    "        distance_mixed_addition = update_with_metric(**get_args(metric_name,df_name,\"A\"))\n",
    "        distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "        \n",
    "        distance_filtd_addition = update_with_metric(**get_args(metric_name,df_name,\"Y\"))\n",
    "        distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Variational Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "distance_trunc_addition[\"tvd_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_mixed_addition[\"tvd_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_filtd_addition[\"tvd_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(yc_ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(yc_ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(yc_ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "distance_trunc_addition[\"yc_tvd_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_mixed_addition[\"yc_tvd_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_filtd_addition[\"yc_tvd_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(yc_new_ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(yc_new_ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_tvd(yc_new_ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "distance_trunc_addition[\"yc_new_tvd_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_mixed_addition[\"yc_new_tvd_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_filtd_addition[\"yc_new_tvd_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singleton-Epps statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_es2(ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_es2(ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_es2(ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "#Adjust the p-values to account for multiple hypothesis testing\n",
    "results_trunc = multitest.multipletests(distance_trunc_results[distance_trunc_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_mixed = multitest.multipletests(distance_mixed_results[distance_mixed_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_filtd = multitest.multipletests(distance_filtd_results[distance_filtd_results.pvalue.notnull()][\"pvalue\"])\n",
    "print(results_trunc[2:4])\n",
    "print(results_mixed[2:4])\n",
    "print(results_filtd[2:4])\n",
    "\n",
    "#Rename\n",
    "distance_trunc_addition[\"es_significant\"] = pd.Series(results_trunc[0],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"es_significant\"] = pd.Series(results_mixed[0],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"es_significant\"] = pd.Series(results_filtd[0],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"es_pvalue\"] = pd.Series(results_trunc[1],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"es_pvalue\"] = pd.Series(results_mixed[1],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"es_pvalue\"] = pd.Series(results_filtd[1],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"es_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_mixed_addition[\"es_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_filtd_addition[\"es_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "\n",
    "distance_trunc_addition[\"log_es_statistic\"] = np.log(distance_trunc_addition[\"es_statistic\"])\n",
    "distance_mixed_addition[\"log_es_statistic\"] = np.log(distance_mixed_addition[\"es_statistic\"])\n",
    "distance_filtd_addition[\"log_es_statistic\"] = np.log(distance_mixed_addition[\"es_statistic\"])\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_es2(yc_ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_es2(yc_ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_es2(yc_ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "#Adjust the p-values to account for multiple hypothesis testing\n",
    "results_trunc = multitest.multipletests(distance_trunc_results[distance_trunc_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_mixed = multitest.multipletests(distance_mixed_results[distance_mixed_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_filtd = multitest.multipletests(distance_filtd_results[distance_filtd_results.pvalue.notnull()][\"pvalue\"])\n",
    "print(results_trunc[2:4])\n",
    "print(results_mixed[2:4])\n",
    "print(results_filtd[2:4])\n",
    "\n",
    "#Rename\n",
    "distance_trunc_addition[\"yc_es_significant\"] = pd.Series(results_trunc[0],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_trunc_addition[\"yc_es_pvalue\"] = pd.Series(results_trunc[1],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_es_significant\"] = pd.Series(results_mixed[0],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_es_pvalue\"] = pd.Series(results_mixed[1],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_es_significant\"] = pd.Series(results_filtd[0],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_es_pvalue\"] = pd.Series(results_filtd[1],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"yc_es_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_trunc_addition[\"yc_log_es_statistic\"] = np.log(distance_trunc_addition[\"yc_es_statistic\"])\n",
    "distance_mixed_addition[\"yc_es_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_mixed_addition[\"yc_log_es_statistic\"] = np.log(distance_mixed_addition[\"yc_es_statistic\"])\n",
    "distance_filtd_addition[\"yc_es_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "distance_filtd_addition[\"yc_log_es_statistic\"] = np.log(distance_mixed_addition[\"yc_es_statistic\"])\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_es2(yc_new_ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_es2(yc_new_ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_es2(yc_new_ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "#Adjust the p-values to account for multiple hypothesis testing\n",
    "results_trunc = multitest.multipletests(distance_trunc_results[distance_trunc_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_mixed = multitest.multipletests(distance_mixed_results[distance_mixed_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_filtd = multitest.multipletests(distance_filtd_results[distance_filtd_results.pvalue.notnull()][\"pvalue\"])\n",
    "print(results_trunc[2:4])\n",
    "print(results_mixed[2:4])\n",
    "print(results_filtd[2:4])\n",
    "\n",
    "#Rename\n",
    "distance_trunc_addition[\"yc_new_es_significant\"] = pd.Series(results_trunc[0],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_trunc_addition[\"yc_new_es_pvalue\"] = pd.Series(results_trunc[1],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_new_es_significant\"] = pd.Series(results_mixed[0],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_new_es_pvalue\"] = pd.Series(results_mixed[1],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_new_es_significant\"] = pd.Series(results_filtd[0],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_new_es_pvalue\"] = pd.Series(results_filtd[1],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"yc_new_es_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_trunc_addition[\"yc_new_log_es_statistic\"] = np.log(distance_trunc_addition[\"yc_new_es_statistic\"])\n",
    "distance_mixed_addition[\"yc_new_es_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_mixed_addition[\"yc_new_log_es_statistic\"] = np.log(distance_mixed_addition[\"yc_new_es_statistic\"])\n",
    "distance_filtd_addition[\"yc_new_es_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "distance_filtd_addition[\"yc_new_log_es_statistic\"] = np.log(distance_mixed_addition[\"yc_new_es_statistic\"])\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KS Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_updated_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "#Adjust the p-values to account for multiple hypothesis testing\n",
    "results_trunc = multitest.multipletests(distance_trunc_results[distance_trunc_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_mixed = multitest.multipletests(distance_mixed_results[distance_mixed_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_filtd = multitest.multipletests(distance_filtd_results[distance_filtd_results.pvalue.notnull()][\"pvalue\"])\n",
    "print(results_trunc[2:4])\n",
    "print(results_mixed[2:4])\n",
    "print(results_filtd[2:4])\n",
    "\n",
    "#Rename\n",
    "distance_trunc_addition[\"ks_significant\"] = pd.Series(results_trunc[0],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_trunc_addition[\"ks_pvalue\"] = pd.Series(results_trunc[1],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"ks_significant\"] = pd.Series(results_mixed[0],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"ks_pvalue\"] = pd.Series(results_mixed[1],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"ks_significant\"] = pd.Series(results_filtd[0],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"ks_pvalue\"] = pd.Series(results_filtd[1],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"ks_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_trunc_addition[\"log_ks_statistic\"] = np.log(distance_trunc_addition[\"ks_statistic\"])\n",
    "distance_mixed_addition[\"ks_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_mixed_addition[\"log_ks_statistic\"] = np.log(distance_mixed_addition[\"ks_statistic\"])\n",
    "distance_filtd_addition[\"ks_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "distance_filtd_addition[\"log_ks_statistic\"] = np.log(distance_filtd_addition[\"ks_statistic\"])\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(yc_ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(yc_ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(yc_ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "#Adjust the p-values to account for multiple hypothesis testing\n",
    "results_trunc = multitest.multipletests(distance_trunc_results[distance_trunc_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_mixed = multitest.multipletests(distance_mixed_results[distance_mixed_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_filtd = multitest.multipletests(distance_filtd_results[distance_filtd_results.pvalue.notnull()][\"pvalue\"])\n",
    "print(results_trunc[2:4])\n",
    "print(results_mixed[2:4])\n",
    "print(results_filtd[2:4])\n",
    "\n",
    "#Rename\n",
    "distance_trunc_addition[\"yc_ks_significant\"] = pd.Series(results_trunc[0],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_trunc_addition[\"yc_ks_pvalue\"] = pd.Series(results_trunc[1],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_ks_significant\"] = pd.Series(results_mixed[0],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_ks_pvalue\"] = pd.Series(results_mixed[1],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_ks_significant\"] = pd.Series(results_filtd[0],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_ks_pvalue\"] = pd.Series(results_filtd[1],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"yc_ks_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_trunc_addition[\"yc_log_ks_statistic\"] = np.log(distance_trunc_addition[\"yc_ks_statistic\"])\n",
    "distance_mixed_addition[\"yc_ks_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_mixed_addition[\"yc_log_ks_statistic\"] = np.log(distance_mixed_addition[\"yc_ks_statistic\"])\n",
    "distance_filtd_addition[\"yc_ks_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "distance_filtd_addition[\"yc_log_ks_statistic\"] = np.log(distance_filtd_addition[\"yc_ks_statistic\"])\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "distance_trunc_addition = pd.DataFrame()\n",
    "distance_mixed_addition = pd.DataFrame()\n",
    "distance_filtd_addition = pd.DataFrame()\n",
    "\n",
    "#Compute statistic\n",
    "\n",
    "distance_trunc_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(yc_new_ratings_baseline_trunc,group[group.flagged=='N'].rating))\n",
    "distance_mixed_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(yc_new_ratings_baseline_mixed,group.rating))\n",
    "distance_filtd_results = yc_new_reviews.groupby(\"businessID\").apply(lambda group: get_ks2(yc_new_ratings_baseline_filtd,group[group.flagged=='Y'].rating))\n",
    "\n",
    "#Adjust the p-values to account for multiple hypothesis testing\n",
    "results_trunc = multitest.multipletests(distance_trunc_results[distance_trunc_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_mixed = multitest.multipletests(distance_mixed_results[distance_mixed_results.pvalue.notnull()][\"pvalue\"])\n",
    "results_filtd = multitest.multipletests(distance_filtd_results[distance_filtd_results.pvalue.notnull()][\"pvalue\"])\n",
    "print(results_trunc[2:4])\n",
    "print(results_mixed[2:4])\n",
    "print(results_filtd[2:4])\n",
    "\n",
    "#Rename\n",
    "distance_trunc_addition[\"yc_new_ks_significant\"] = pd.Series(results_trunc[0],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_trunc_addition[\"yc_new_ks_pvalue\"] = pd.Series(results_trunc[1],index=distance_trunc_results[distance_trunc_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_new_ks_significant\"] = pd.Series(results_mixed[0],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_mixed_addition[\"yc_new_ks_pvalue\"] = pd.Series(results_mixed[1],index=distance_mixed_results[distance_mixed_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_new_ks_significant\"] = pd.Series(results_filtd[0],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "distance_filtd_addition[\"yc_new_ks_pvalue\"] = pd.Series(results_filtd[1],index=distance_filtd_results[distance_filtd_results.pvalue.notnull()].index)\n",
    "\n",
    "distance_trunc_addition[\"yc_new_ks_statistic\"] = distance_trunc_results[\"statistic\"]\n",
    "distance_trunc_addition[\"yc_new_log_ks_statistic\"] = np.log(distance_trunc_addition[\"yc_new_ks_statistic\"])\n",
    "distance_mixed_addition[\"yc_new_ks_statistic\"] = distance_mixed_results[\"statistic\"]\n",
    "distance_mixed_addition[\"yc_new_log_ks_statistic\"] = np.log(distance_mixed_addition[\"yc_new_ks_statistic\"])\n",
    "distance_filtd_addition[\"yc_new_ks_statistic\"] = distance_filtd_results[\"statistic\"]\n",
    "distance_filtd_addition[\"yc_new_log_ks_statistic\"] = np.log(distance_filtd_addition[\"yc_new_ks_statistic\"])\n",
    "\n",
    "distance_trunc = pd.concat([distance_trunc,distance_trunc_addition],axis=1)\n",
    "distance_mixed = pd.concat([distance_mixed,distance_mixed_addition],axis=1)\n",
    "distance_filtd = pd.concat([distance_filtd,distance_filtd_addition],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_filtd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(distance_trunc.log_es_statistic,label=\"ES truncated\",rug=True,hist=True)\n",
    "sns.distplot(distance_mixed.log_es_statistic,label=\"ES mixed\",rug=True,hist=True)\n",
    "sns.distplot(distance_filtd.log_es_statistic,label=\"ES filtered\",rug=True,hist=True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "sns.distplot(distance_trunc.ks_statistic,label=\"KS truncated\",rug=True,hist=True)\n",
    "sns.distplot(distance_mixed.ks_statistic,label=\"KS mixed\",rug=True,hist=True)\n",
    "sns.distplot(distance_filtd.ks_statistic,label=\"KS filtered\",rug=True,hist=True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "sns.distplot(distance_trunc.tvd_statistic,label=\"TVD truncated\",rug=True,hist=True)\n",
    "sns.distplot(distance_mixed.tvd_statistic,label=\"TVD mixed\",rug=True,hist=True)\n",
    "sns.distplot(distance_filtd.tvd_statistic,label=\"TVD filtered\",rug=True,hist=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,1,0.01)\n",
    "\n",
    "kwargs = {\"cumulative\": True}\n",
    "\n",
    "sns.distplot(distance_trunc.es_pvalue,label=\"ES truncated\",rug=True,hist=True,bins=bins,hist_kws=kwargs,kde_kws=kwargs)\n",
    "sns.distplot(distance_mixed.es_pvalue,label=\"ES mixed\",rug=True,hist=True,bins=bins,hist_kws=kwargs,kde_kws=kwargs)\n",
    "sns.distplot(distance_filtd.es_pvalue,label=\"ES filtered\",rug=True,hist=True,bins=bins,hist_kws=kwargs,kde_kws=kwargs)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "sns.distplot(distance_trunc.ks_pvalue,label=\"KS truncated\",rug=True,hist=True,bins=bins,hist_kws=kwargs,kde_kws=kwargs)\n",
    "sns.distplot(distance_mixed.ks_pvalue,label=\"KS mixed\",rug=True,hist=True,bins=bins,hist_kws=kwargs,kde_kws=kwargs)\n",
    "sns.distplot(distance_filtd.ks_pvalue,label=\"KS filtered\",rug=True,hist=True,bins=bins,hist_kws=kwargs,kde_kws=kwargs)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin p-value data into different hypothesis levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_pvalue(pvalue):\n",
    "    for p in [0.001,0.005,0.01,0.05]:\n",
    "        if pvalue < p:\n",
    "            return (\"%0.3f\" % p).rstrip(\"0\")\n",
    "    return \"Not significant\"\n",
    "distance_trunc[\"ks_pvalue_bin\"] = distance_trunc[\"ks_pvalue\"].apply(bin_pvalue)\n",
    "distance_trunc[\"es_pvalue_bin\"] = distance_trunc[\"es_pvalue\"].apply(bin_pvalue)\n",
    "distance_mixed[\"ks_pvalue_bin\"] = distance_mixed[\"ks_pvalue\"].apply(bin_pvalue)\n",
    "distance_mixed[\"es_pvalue_bin\"] = distance_mixed[\"es_pvalue\"].apply(bin_pvalue)\n",
    "distance_filtd[\"ks_pvalue_bin\"] = distance_filtd[\"ks_pvalue\"].apply(bin_pvalue)\n",
    "distance_filtd[\"es_pvalue_bin\"] = distance_filtd[\"es_pvalue\"].apply(bin_pvalue)\n",
    "\n",
    "\n",
    "distance_trunc[\"yc_ks_pvalue_bin\"] = distance_trunc[\"yc_ks_pvalue\"].apply(bin_pvalue)\n",
    "distance_trunc[\"yc_es_pvalue_bin\"] = distance_trunc[\"yc_es_pvalue\"].apply(bin_pvalue)\n",
    "distance_mixed[\"yc_ks_pvalue_bin\"] = distance_mixed[\"yc_ks_pvalue\"].apply(bin_pvalue)\n",
    "distance_mixed[\"yc_es_pvalue_bin\"] = distance_mixed[\"yc_es_pvalue\"].apply(bin_pvalue)\n",
    "distance_filtd[\"yc_ks_pvalue_bin\"] = distance_filtd[\"yc_ks_pvalue\"].apply(bin_pvalue)\n",
    "distance_filtd[\"yc_es_pvalue_bin\"] = distance_filtd[\"yc_es_pvalue\"].apply(bin_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_trunc = distance_trunc.rename(columns={\"%s\" % colname: \"%s_trunc\" % colname for colname in distance_trunc})\n",
    "distance_mixed = distance_mixed.rename(columns={\"%s\" % colname: \"%s_mixed\" % colname for colname in distance_mixed})\n",
    "distance_filtd = distance_filtd.rename(columns={\"%s\" % colname: \"%s_filtd\" % colname for colname in distance_filtd})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a dataframe for doing stats on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances = pd.concat([yc_businesses,distance_trunc, distance_mixed, distance_filtd], join=\"inner\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would it look like if ratings were drawn randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the distances change over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=\"ks_statistic_trunc\",x=\"yc_ks_statistic_trunc\",data=businesses_distances,label=\"KS Trunc\")\n",
    "sns.scatterplot(y=\"ks_statistic_mixed\",x=\"yc_ks_statistic_mixed\",data=businesses_distances,label=\"KS Mixed\")\n",
    "sns.scatterplot(y=\"ks_statistic_filtd\",x=\"yc_ks_statistic_filtd\",data=businesses_distances,label=\"KS Filtered\")\n",
    "plt.show()\n",
    "sns.scatterplot(y=\"log_es_statistic_trunc\",x=\"yc_log_es_statistic_trunc\",data=businesses_distances,label=\"ES Trunc\")\n",
    "sns.scatterplot(y=\"log_es_statistic_mixed\",x=\"yc_log_es_statistic_mixed\",data=businesses_distances,label=\"ES Mixed\")\n",
    "sns.scatterplot(y=\"log_es_statistic_filtd\",x=\"yc_log_es_statistic_filtd\",data=businesses_distances,label=\"ES Filtered\")\n",
    "plt.show()\n",
    "sns.scatterplot(y=\"tvd_statistic_trunc\",x=\"yc_tvd_statistic_trunc\",data=businesses_distances,label=\"TVD Trunc\")\n",
    "sns.scatterplot(y=\"tvd_statistic_mixed\",x=\"yc_tvd_statistic_mixed\",data=businesses_distances,label=\"TVD Mixed\")\n",
    "sns.scatterplot(y=\"tvd_statistic_filtd\",x=\"yc_tvd_statistic_filtd\",data=businesses_distances,label=\"TVD Filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=\"yc_new_ks_statistic_trunc\",x=\"yc_ks_statistic_trunc\",data=businesses_distances,label=\"KS Trunc\")\n",
    "sns.scatterplot(y=\"yc_new_ks_statistic_mixed\",x=\"yc_ks_statistic_mixed\",data=businesses_distances,label=\"KS Mixed\")\n",
    "sns.scatterplot(y=\"yc_new_ks_statistic_filtd\",x=\"yc_ks_statistic_filtd\",data=businesses_distances,label=\"KS Filtered\")\n",
    "plt.show()\n",
    "sns.scatterplot(y=\"yc_new_log_es_statistic_trunc\",x=\"yc_log_es_statistic_trunc\",data=businesses_distances,label=\"ES Trunc\")\n",
    "sns.scatterplot(y=\"yc_new_log_es_statistic_mixed\",x=\"yc_log_es_statistic_mixed\",data=businesses_distances,label=\"ES Mixed\")\n",
    "sns.scatterplot(y=\"yc_new_log_es_statistic_filtd\",x=\"yc_log_es_statistic_filtd\",data=businesses_distances,label=\"ES Filtered\")\n",
    "plt.show()\n",
    "sns.scatterplot(y=\"yc_new_tvd_statistic_trunc\",x=\"yc_tvd_statistic_trunc\",data=businesses_distances,label=\"TVD Trunc\")\n",
    "sns.scatterplot(y=\"yc_new_tvd_statistic_mixed\",x=\"yc_tvd_statistic_mixed\",data=businesses_distances,label=\"TVD Mixed\")\n",
    "sns.scatterplot(y=\"yc_new_tvd_statistic_filtd\",x=\"yc_tvd_statistic_filtd\",data=businesses_distances,label=\"TVD Filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's capture the cluster on the right for ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_bottom_left_outliers(data1,data2):\n",
    "    for idx,v1 in data1.iteritems():\n",
    "        v2 = data2[idx]\n",
    "        if v1 > 7.5 and v2 < 8:\n",
    "            yield idx\n",
    "\n",
    "t_outliers = pd.Series(grab_bottom_left_outliers(businesses_distances.yc_log_es_statistic_trunc, businesses_distances.log_es_statistic_trunc))\n",
    "m_outliers = pd.Series(grab_bottom_left_outliers(businesses_distances.yc_log_es_statistic_mixed, businesses_distances.log_es_statistic_mixed))\n",
    "f_outliers = pd.Series(grab_bottom_left_outliers(businesses_distances.yc_log_es_statistic_filtd, businesses_distances.log_es_statistic_filtd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t_outliers),len(m_outliers),len(f_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(t_outliers) & set(f_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "businesses_distances.loc[set(t_outliers) & set(f_outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_outliers_bd = businesses_distances.loc[t_outliers]\n",
    "bd_no_outliers = businesses_distances.loc[set(businesses_distances.index) - set(t_outliers)]\n",
    "bins = np.arange(0.75,6,0.5)\n",
    "display(Markdown(\"#### New Rating\"))\n",
    "display(Markdown(\"Distance: %f (p=%f)\" % scipy.stats.epps_singleton_2samp(t_outliers_bd.rating,businesses_distances.rating)))\n",
    "sns.distplot(t_outliers_bd.rating,label=\"Trunc outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(businesses_distances.rating,label=\"Trunc\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(bd_no_outliers.rating,label=\"Trunc Non-outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "plt.legend()\n",
    "plt.show()\n",
    "display(Markdown(\"#### Old Rating\"))\n",
    "display(Markdown(\"Distance: %f (p=%f)\" % scipy.stats.epps_singleton_2samp(t_outliers_bd.yc_rating,businesses_distances.yc_rating)))\n",
    "sns.distplot(t_outliers_bd.yc_rating,label=\"Trunc outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(businesses_distances.yc_rating,label=\"Trunc\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(bd_no_outliers.yc_rating,label=\"Trunc Non-outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "plt.legend()\n",
    "plt.show()\n",
    "display(Markdown(\"#### New Review Count\"))\n",
    "display(Markdown(\"Distance: %f (p=%f)\" % scipy.stats.epps_singleton_2samp(t_outliers_bd.review_count,businesses_distances.review_count)))\n",
    "bins = np.exp(np.arange(1,np.log(businesses_distances.review_count.max()), 1))\n",
    "sns.distplot(t_outliers_bd.review_count,label=\"Trunc outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(businesses_distances.review_count,label=\"Trunc\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(bd_no_outliers.review_count,label=\"Trunc Non-outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "display(Markdown(\"#### Old Review Count\"))\n",
    "display(Markdown(\"Distance: %f (p=%f)\" % scipy.stats.epps_singleton_2samp(t_outliers_bd.yc_reviewCount,businesses_distances.yc_reviewCount)))\n",
    "sns.distplot(t_outliers_bd.yc_reviewCount,label=\"Trunc outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(businesses_distances.yc_reviewCount,label=\"Trunc\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(bd_no_outliers.yc_reviewCount,label=\"Trunc Non-outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#TODO\n",
    "display(Markdown(\"#### New Filtered Ratio\"))\n",
    "display(Markdown(\"Distance (KS): %f (p=%f)\" % scipy.stats.ks_2samp(t_outliers_bd.filtered_ratio,businesses_distances.filtered_ratio)))\n",
    "bins = np.arange(0,1.01,0.01)\n",
    "sns.distplot(t_outliers_bd.filtered_ratio,label=\"Trunc outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(businesses_distances.filtered_ratio,label=\"Trunc\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(bd_no_outliers.filtered_ratio,label=\"Trunc Non-outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "plt.legend()\n",
    "plt.show()\n",
    "display(Markdown(\"#### Old Filtered Ratio\"))\n",
    "display(Markdown(\"Distance (KS): %f (p=%f)\" % scipy.stats.ks_2samp(t_outliers_bd.yc_filtered_ratio,businesses_distances.yc_filtered_ratio)))\n",
    "sns.distplot(t_outliers_bd.yc_filtered_ratio,label=\"Trunc outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(businesses_distances.yc_filtered_ratio,label=\"Trunc\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "sns.distplot(bd_no_outliers.yc_filtered_ratio,label=\"Trunc Non-outliers\",kde=False,norm_hist=True,bins=bins,hist_kws={\"cumulative\": True})\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These outliers have low review counts, but not atypical ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([t_outliers_bd.groupby(\"yc_type\").size(), businesses_distances.groupby(\"yc_type\").size()],axis=1).fillna(0)\n",
    "scipy.stats.fisher_exact(df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier_type(series,outlier_bids=None):\n",
    "    bid = series.name\n",
    "    return bid in outlier_bids\n",
    "businesses_distances.apply(functools.partial(is_outlier_type,outlier_bids=set(t_outliers)),axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances[\"es_outlier_trunc\"] = businesses_distances.apply(functools.partial(is_outlier_type,outlier_bids=set(t_outliers)),axis=1)\n",
    "businesses_distances[\"es_outlier_mixed\"] = businesses_distances.apply(functools.partial(is_outlier_type,outlier_bids=set(m_outliers)),axis=1)\n",
    "businesses_distances[\"es_outlier_filtd\"] = businesses_distances.apply(functools.partial(is_outlier_type,outlier_bids=set(f_outliers)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference by type is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When we stratify by low review count, do the results hold up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the distances vary across types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"ks_statistic_trunc\",y=\"ks_statistic_mixed\",data=businesses_distances,label=\"KS\")\n",
    "plt.show()\n",
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"es_statistic_mixed\",data=businesses_distances,label=\"ES\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "sns.scatterplot(x=\"ks_statistic_trunc\",y=\"es_statistic_trunc\",data=businesses_distances,label=\"Trunc\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "sns.scatterplot(x=\"ks_statistic_mixed\",y=\"es_statistic_mixed\",data=businesses_distances,label=\"Mixed\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantize the `price` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances[\"price\"] = businesses_distances[\"price\"].apply(lambda x: len(x) if type(x) is str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = businesses_distances[\"price\"].mean() // 1\n",
    "businesses_distances[\"price\"] = businesses_distances[\"price\"].apply(lambda x: m if math.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perturb discrete columns for better plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances[\"price_perturbed\"] = businesses_distances.price.apply(lambda x: x + random.random() * 0.5 - 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances[\"rating_perturbed\"] = businesses_distances.rating.apply(lambda x: x + random.random() * 0.25 - 0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort values and get needed log-based columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances = businesses_distances.sort_values(\"es_pvalue_trunc\")\n",
    "businesses_distances.to_pickle(\"../data/pickles/yelpchi_business_data_with_distances.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the statistic relate to p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"es_pvalue_trunc\",data=businesses_distances,label=\"All data\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_mixed\",y=\"es_pvalue_mixed\",data=businesses_distances,label=\"All data\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances[businesses_distances.es_statistic_trunc.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"review_count\",data=businesses_distances,label=\"All data\",hue=\"es_pvalue_bin_trunc\")\n",
    "#sns.scatterplot(x=\"statistic\",y=\"review_count\",data=businesses_distances_sig,label=\"Signficant data\",hue=\"pvalue_bin\")\n",
    "#sns.scatterplot(x=\"statistic\",y=\"review_count\",data=businesses_distances_very_sig,label=\"Very signficant data\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_trunc, businesses_distances.review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"yc_es_statistic_trunc\",y=\"yc_reviewCount\",data=businesses_distances,label=\"All data\",hue=\"yc_es_pvalue_bin_trunc\")\n",
    "#sns.scatterplot(x=\"statistic\",y=\"review_count\",data=businesses_distances_sig,label=\"Signficant data\",hue=\"pvalue_bin\")\n",
    "#sns.scatterplot(x=\"statistic\",y=\"review_count\",data=businesses_distances_very_sig,label=\"Very signficant data\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "df1 = businesses_distances[businesses_distances.yc_es_statistic_trunc.notnull()]\n",
    "df2 = df1.loc[set(df1.index) - set(t_outliers)]\n",
    "print(\"With outliers: %f (p=%f)\\nWithout outliers: %f (p=%f)\" % (scipy.stats.pearsonr(df1.yc_es_statistic_trunc, df1.yc_reviewCount) + scipy.stats.pearsonr(df2.yc_es_statistic_trunc, df2.yc_reviewCount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_mixed\",y=\"review_count\",data=businesses_distances.sort_values(\"es_pvalue_mixed\"),label=\"All data\",hue=\"es_pvalue_bin_mixed\")\n",
    "#sns.scatterplot(x=\"statistic\",y=\"review_count\",data=businesses_distances_sig,label=\"Signficant data\",hue=\"pvalue_bin\")\n",
    "#sns.scatterplot(x=\"statistic\",y=\"review_count\",data=businesses_distances_very_sig,label=\"Very signficant data\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_mixed, businesses_distances.review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"price_perturbed\",data=businesses_distances,hue=\"es_pvalue_bin_trunc\")\n",
    "#sns.scatterplot(x=\"es_statistic_trunc\",y=\"price_perturbed\",data=businesses_distances_sig,label=\"Signficant data\")\n",
    "plt.xscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_trunc, businesses_distances.price)\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_distances[\"isChainReduced\"] = businesses_distances[\"isChain\"].apply({\"0\": 0, \"1\": 1, \"2\": 1, \"3\": 1, \"None\": 0}.get)\n",
    "businesses_distances[\"isChainReducedPerturbed\"] = businesses_distances.isChainReduced.apply(lambda x: x + random.random() * 0.5 - 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"isChainReducedPerturbed\",data=businesses_distances,hue=\"es_pvalue_bin_trunc\")\n",
    "#sns.scatterplot(x=\"es_statistic_trunc\",y=\"price_perturbed\",data=businesses_distances_sig,label=\"Signficant data\")\n",
    "plt.xscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.log_es_statistic_trunc, businesses_distances.isChainReduced)\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palette = sns.cubehelix_palette(len(businesses_distances.pvalue_bin.unique()), rot=-.4, light=0.6, dark=0.8)\n",
    "palette = sns.color_palette(\"GnBu_d\",n_colors=len(businesses_distances.es_pvalue_bin_trunc.unique()))\n",
    "sns.scatterplot(x=\"coordinates.longitude\",y=\"coordinates.latitude\",data=businesses_distances,hue=\"es_pvalue_bin_trunc\",palette=palette)\n",
    "#sns.scatterplot(x=\"coordinates.longitude\",y=\"coordinates.latitude\",data=businesses_distances_sig,hue=\"log_statistic\",cmap=palette)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.05),loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.cubehelix_palette(8, start=2, rot=0, dark=0, light=.95, reverse=True)\n",
    "sns.kdeplot(businesses_distances[\"coordinates.longitude\"],businesses_distances[\"coordinates.latitude\"],label=\"Non-signficant points\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.05),loc=\"upper left\")\n",
    "plt.show()\n",
    "sns.kdeplot(businesses_distances[businesses_distances.es_pvalue_trunc < 0.05][\"coordinates.longitude\"],businesses_distances[businesses_distances.es_pvalue_trunc < 0.05][\"coordinates.latitude\"],label=\"Significant points\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.05),loc=\"upper left\")\n",
    "plt.show()\n",
    "sns.kdeplot(businesses_distances[businesses_distances.es_pvalue_mixed < 0.05][\"coordinates.longitude\"],businesses_distances[businesses_distances.es_pvalue_mixed < 0.05][\"coordinates.latitude\"],label=\"Significant points\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.05),loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"rating_perturbed\",data=businesses_distances)\n",
    "plt.xscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_trunc, businesses_distances.rating)\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this really isn't that surprising -- is there a correlation between your average rating and the distribution of your ratings? Of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_mixed\",y=\"rating_perturbed\",data=businesses_distances)\n",
    "plt.xscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_mixed, businesses_distances.rating)\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_trunc\",y=\"filtered_ratio\",data=businesses_distances)\n",
    "plt.xscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_trunc, businesses_distances.filtered_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"es_statistic_mixed\",y=\"filtered_ratio\",data=businesses_distances)\n",
    "plt.xscale(\"log\")\n",
    "scipy.stats.pearsonr(businesses_distances.es_statistic_mixed, businesses_distances.filtered_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot each business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_ct_by_business = yc_updated_reviews.groupby(\"businessID\").content.size()\n",
    "yc_updated_reviews[\"business_review_count\"] = yc_updated_reviews.apply(lambda x: review_ct_by_business[x.businessID], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month = pd.Timedelta(\"30 days\")\n",
    "three_months = pd.Timedelta(\"90 days\")\n",
    "def reviews_at_time(df, date):\n",
    "    \n",
    "    six_month_window = df[(df.date < date + three_months) & (df.date >= date - three_months)]\n",
    "    \n",
    "    if len(six_month_window) == 0:\n",
    "        print(date)\n",
    "    \n",
    "    s = pd.Series(dtype=\"object\")\n",
    "    \n",
    "    s[\"binned_rating\"] = round(six_month_window.rating.mean() * 2) // 2\n",
    "    s[\"ratings\"] = list(six_month_window.rating)\n",
    "    s[\"indexes\"] = list(six_month_window.index.values)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_six_month_windows_binned = {\n",
    "    i: [] for i in np.arange(1,5.5,.5)\n",
    "}\n",
    "for business_id, group in tqdm(yc_updated_reviews.sort_values(\"business_review_count\",ascending=False).groupby(\"businessID\",sort=False),total=len(yc_updated_reviews[yc_updated_reviews.flagged == 'N'].businessID.unique())):\n",
    "    \n",
    "    \n",
    "    dates = pd.Series(group.date.unique()).sort_values()\n",
    "    \n",
    "    i = 0 #Before\n",
    "    j = 0 #After\n",
    "    \n",
    "    dates_alt = []\n",
    "    \n",
    "    date = dates.min()\n",
    "    while date < dates.max():\n",
    "        while i+1 < len(dates) and dates.iloc[i+1] < date:\n",
    "            i += 1\n",
    "        while j+1 < len(dates) and dates.iloc[j+1] > date:\n",
    "            j += 1\n",
    "        \n",
    "        if date - dates.iloc[i] <= three_months or dates.iloc[j] - date < three_months:\n",
    "            dates_alt.append(date)\n",
    "        date += one_month\n",
    "    dates_alt.append(dates.max())\n",
    "    \n",
    "    dates = pd.Series(dates_alt)\n",
    "    \n",
    "    windows = dates.apply(functools.partial(reviews_at_time,group))\n",
    "    #display(windows)\n",
    "    for idx, window in windows.iterrows():\n",
    "        all_six_month_windows_binned[window[\"binned_rating\"]] += list(window.ratings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three_months = pd.to_timedelta(\"90 days\")\n",
    "\n",
    "def rating_at_time(df, date):\n",
    "    s = pd.Series(dtype='object')\n",
    "    \n",
    "    window = df[df.date <= date]\n",
    "    \n",
    "    s[\"date\"] = date\n",
    "    s[\"perc_filtered\"] = len(window[window.flagged == \"Y\"]) / len(window)\n",
    "    s[\"review_count\"] = len(window)\n",
    "    s[\"recommended_review_count\"] = len(window[window.flagged == \"N\"])\n",
    "    s[\"filtered_review_count\"] = len(window[window.flagged == \"Y\"])\n",
    "    \n",
    "    six_month_window = df[(df.date < date + three_months) & (df.date >= date - three_months)]\n",
    "    \n",
    "    if len(window[window.flagged == \"N\"].rating) > 0:\n",
    "        s[\"rating\"] = window[window.flagged == \"N\"].rating.mean()\n",
    "        s[\"smooth_avg_6mo\"] = six_month_window[six_month_window.flagged == \"N\"].rating.mean()    \n",
    "        \n",
    "    if len(window[window.flagged == \"N\"].rating) > 1:\n",
    "        sigma = window[window.flagged == \"N\"].rating.std()\n",
    "\n",
    "        for i in range(1,3+1):\n",
    "            s[f\"rating_plus_{i}_sigma\"] = min(s.rating + i * sigma,5)\n",
    "            s[f\"rating_plus_{i}_sigma_of_1\"] = (s[f\"rating_plus_{i}_sigma\"] - 1) / 4\n",
    "\n",
    "            s[f\"rating_minus_{i}_sigma\"] = max(1,s.rating - i * sigma)\n",
    "            s[f\"rating_minus_{i}_sigma_of_1\"] = (s[f\"rating_minus_{i}_sigma\"] - 1) / 4\n",
    "\n",
    "\n",
    "        s[\"rating_of_1\"] = (s.rating - 1) / 4\n",
    "        s[\"smooth_avg_6mo_of_1\"] = (s.smooth_avg_6mo - 1) / 4\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        s[\"es\"] = scipy.stats.epps_singleton_2samp(six_month_window.rating, df.rating)[1]\n",
    "        s[\"binned_rating\"] = round(six_month_window.rating.mean() * 2) // 2\n",
    "        s[\"es_bin\"] = scipy.stats.epps_singleton_2samp(six_month_window.rating, all_six_month_windows_binned[s[\"binned_rating\"]])[1]\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        #display(window.rating)\n",
    "        #display(df.rating)\n",
    "        #raise\n",
    "        pass\n",
    "    \n",
    "    return s\n",
    "\n",
    "failures = []\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator(bymonth=None, bymonthday=1, interval=3)  # every 3 months\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "start_time = datetime.datetime(year=yc_updated_reviews.date.min().year,month=1,day=1)\n",
    "end_time = datetime.datetime(year=yc_updated_reviews.date.max().year+1,month=1,day=1)\n",
    "\n",
    "for business_id, group in yc_updated_reviews.sort_values(\"business_review_count\").groupby(\"businessID\",sort=False):\n",
    "    summary = pd.Series(group.date.unique()).apply(functools.partial(rating_at_time,group))\n",
    "    summary = summary[summary.rating.notnull()]\n",
    "    #display(summary)\n",
    "    try:\n",
    "        max_reviews = summary.review_count.max()\n",
    "        \n",
    "        business = yc_businesses.loc[business_id]\n",
    "        business_alias = business.alias\n",
    "        business_name = business.name\n",
    "        \n",
    "        print(f\"{business_name}\")\n",
    "        \n",
    "        summary[\"review_count_of_1\"] = (summary.review_count / max_reviews).astype(\"float\")\n",
    "        \n",
    "        six_month_sigma = summary[\"smooth_avg_6mo\"].std()\n",
    "        i = 1\n",
    "        summary[f\"six_month_rating_plus_{i}_sigma_of_1\"] = (((summary[\"rating\"] + i * six_month_sigma )- 1) / 4).apply(lambda x: min(x,1))\n",
    "        summary[f\"six_month_rating_minus_{i}_sigma_of_1\"] = (((summary[\"rating\"] - i * six_month_sigma )- 1) / 4).apply(lambda x: max(x,0))\n",
    "        \n",
    "        \n",
    "#         for i in range(1,2):\n",
    "#             sns.lineplot(x=\"date\",y=f\"rating_plus_{i}_sigma_of_1\",data=summary,label=None,color=\"black\")\n",
    "#             ax = sns.lineplot(x=\"date\",y=f\"rating_minus_{i}_sigma_of_1\",data=summary,label=None,color=\"black\")\n",
    "#             ax.lines[len(ax.lines)-1].set_linestyle(\"--\")\n",
    "#             ax.lines[len(ax.lines)-2].set_linestyle(\"--\")\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = 15, 5\n",
    "        #fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "        fig, ax1 = plt.subplots(ncols=1, sharey=True)\n",
    "        ax2 = ax1\n",
    "        \n",
    "        try:\n",
    "            sns.lineplot(x=\"date\",y=\"es\",data=summary,label=\"Epps-Singleton\",ax=ax2)\n",
    "            ax = sns.lineplot(x=\"date\",y=\"es_bin\",data=summary,label=\"Epps-Singleton (binned)\",ax=ax2)\n",
    "            ax.lines[len(ax.lines)-1].set_linestyle(\"--\")\n",
    "            ax.lines[len(ax.lines)-2].set_linestyle(\"--\")\n",
    "#             ax.tick_params(which=\"both\", bottom=True)\n",
    "#             ax.xaxis.set_major_locator(years)\n",
    "#             ax.xaxis.set_major_formatter(years_fmt)\n",
    "#             ax.xaxis.set_minor_locator(months)\n",
    "#             ax.figure.autofmt_xdate()\n",
    "#             ax.set_xlim(start_time,end_time)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for i in range(1,2):\n",
    "            sns.lineplot(x=\"date\",y=f\"six_month_rating_plus_{i}_sigma_of_1\",data=summary,label=None,color=\"black\",ax=ax1)\n",
    "            ax = sns.lineplot(x=\"date\",y=f\"six_month_rating_minus_{i}_sigma_of_1\",data=summary,label=None,color=\"black\",ax=ax1)\n",
    "            ax.lines[len(ax.lines)-1].set_linestyle(\"--\")\n",
    "            ax.lines[len(ax.lines)-2].set_linestyle(\"--\")\n",
    "\n",
    "        sns.lineplot(x=\"date\",y=\"rating_of_1\",data=summary,label=\"Rating\",ax=ax1)\n",
    "        sns.lineplot(x=\"date\",y=\"perc_filtered\",data=summary,label=\"Perc filtered\",ax=ax1)\n",
    "        sns.lineplot(x=\"date\",y=\"review_count_of_1\",data=summary,label=\"Reviews proportion of max\",ax=ax1)\n",
    "        sns.lineplot(x=\"date\",y=\"smooth_avg_6mo_of_1\",data=summary,label=\"6-month rolling average\",ax=ax1)\n",
    "        \n",
    "#         ax.tick_params(which=\"both\", bottom=True)\n",
    "#         ax.xaxis.set_major_locator(years)\n",
    "#         ax.xaxis.set_major_formatter(years_fmt)\n",
    "#         ax.xaxis.set_minor_locator(months)\n",
    "#         ax.figure.autofmt_xdate()\n",
    "        \n",
    "#         ax.set_title(f\"Max reviews: {max_reviews}\\nBusiness alias: {business_alias}\")\n",
    "#         ax.legend(bbox_to_anchor=(0, -0.15), loc=2, borderaxespad=0.)\n",
    "#         ax.set_xlim(start_time,end_time)\n",
    "        \n",
    "        ax.tick_params(which=\"both\", bottom=True)\n",
    "        ax.xaxis.set_major_locator(years)\n",
    "        ax.xaxis.set_major_formatter(years_fmt)\n",
    "        ax.xaxis.set_minor_locator(months)\n",
    "        ax.figure.autofmt_xdate()\n",
    "        \n",
    "        ax.set_title(f\"Max reviews: {max_reviews}\\nBusiness alias: {business_alias}\")\n",
    "        ax.legend(bbox_to_anchor=(0, -0.15), loc=2, borderaxespad=0.)\n",
    "        ax.set_xlim(start_time,end_time)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print(business_id)\n",
    "        display(summary)\n",
    "        failures.append((business_id, summary))\n",
    "        plt.clf()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how this does when we look at only the most typical reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we look at reviews in unusual activity periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews_rating = yc_updated_reviews.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month = pd.Timedelta(\"30 days\")\n",
    "\n",
    "yc_updated_reviews_rating[\"tvd_atypical_windows\"] = 0\n",
    "yc_updated_reviews_rating[\"tvd_windows\"] = 0\n",
    "\n",
    "tvd_distances = collections.defaultdict(list)\n",
    "\n",
    "total = len(yc_updated_reviews.businessID.unique())\n",
    "\n",
    "tvd_all_windows = []\n",
    "\n",
    "for business_id, group in tqdm(yc_updated_reviews.sample(frac=1).groupby(\"businessID\",sort=False),total=total):\n",
    "    dates = pd.Series(group.date.unique()).sort_values()\n",
    "    \n",
    "    i = 0 #Before\n",
    "    j = 0 #After\n",
    "    \n",
    "    dates_alt = []\n",
    "    \n",
    "    date = dates.min()\n",
    "    while date < dates.max():\n",
    "        while i+1 < len(dates) and dates.iloc[i+1] < date:\n",
    "            i += 1\n",
    "        while j+1 < len(dates) and dates.iloc[j+1] > date:\n",
    "            j += 1\n",
    "        \n",
    "        if date - dates.iloc[i] <= three_months or dates.iloc[j] - date < three_months:\n",
    "            dates_alt.append(date)\n",
    "        date += one_month\n",
    "    dates_alt.append(dates.max())\n",
    "    \n",
    "    dates = pd.Series(dates_alt)\n",
    "        \n",
    "    \n",
    "    windows = dates.apply(functools.partial(reviews_at_time,group))\n",
    "    #display(windows)\n",
    "    \n",
    "    for idx, window in windows.iterrows():\n",
    "        if len(window.ratings) < 5:\n",
    "            continue\n",
    "        try:\n",
    "            distance = total_variational_distance(window.ratings,all_six_month_windows_binned[window[\"binned_rating\"]])\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue\n",
    "            \n",
    "        tvd_all_windows.append((distance,window))\n",
    "        \n",
    "        \n",
    "        yc_updated_reviews_rating.loc[window.indexes][\"tvd_windows\"] += 1\n",
    "        \n",
    "        for i in window.indexes:\n",
    "            tvd_distances[i].append(distance)\n",
    "        \n",
    "        if distance > 0.95:\n",
    "            yc_updated_reviews_rating.loc[window.indexes][\"tvd_atypical_windows\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "filtered_ratios = []\n",
    "for distance,window in tvd_all_windows:\n",
    "    reviews = yc_updated_reviews_rating.loc[window.indexes]\n",
    "    counts = reviews.groupby(\"flagged\").size()\n",
    "    try:\n",
    "        filtered_ratio = counts.loc[\"Y\"] / len(reviews)\n",
    "    except KeyError:\n",
    "        filtered_ratio = 0\n",
    "    distances.append(distance)\n",
    "    filtered_ratios.append(filtered_ratio)\n",
    "    \n",
    "distances = pd.Series(distances).rename(\"Distance\")\n",
    "filtered_ratios = pd.Series(filtered_ratios).rename(\"Filtered Ratio\")\n",
    "    \n",
    "sns.scatterplot(distances,filtered_ratios)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = filtered_ratios.quantile(0.25)\n",
    "q2 = filtered_ratios.quantile(0.50)\n",
    "q3 = filtered_ratios.quantile(0.75)\n",
    "\n",
    "def get_quartile(x):\n",
    "    if x < q1:\n",
    "        return \"Q1\"\n",
    "    elif x < q2:\n",
    "        return \"Q2\"\n",
    "    elif x < q3:\n",
    "        return \"Q3\"\n",
    "    else:\n",
    "        return \"Q4\"\n",
    "\n",
    "sns.violinplot(y=distances,x=filtered_ratios.map(get_quartile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epps-Singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews_rating[\"atypical_windows\"] = 0\n",
    "yc_updated_reviews_rating[\"windows\"] = 0\n",
    "\n",
    "pvalues = collections.defaultdict(list)\n",
    "\n",
    "total = len(yc_updated_reviews.businessID.unique())\n",
    "\n",
    "all_windows = []\n",
    "\n",
    "for business_id, group in tqdm(yc_updated_reviews.sample(frac=1).groupby(\"businessID\",sort=False),total=total):\n",
    "    dates = pd.Series(group.date.unique()).sort_values()\n",
    "    \n",
    "    i = 0 #Before\n",
    "    j = 0 #After\n",
    "    \n",
    "    dates_alt = []\n",
    "    \n",
    "    date = dates.min()\n",
    "    while date < dates.max():\n",
    "        while i+1 < len(dates) and dates.iloc[i+1] < date:\n",
    "            i += 1\n",
    "        while j+1 < len(dates) and dates.iloc[j+1] > date:\n",
    "            j += 1\n",
    "        \n",
    "        if date - dates.iloc[i] <= three_months or dates.iloc[j] - date < three_months:\n",
    "            dates_alt.append(date)\n",
    "        date += one_month\n",
    "    dates_alt.append(dates.max())\n",
    "    \n",
    "    dates = pd.Series(dates_alt)\n",
    "        \n",
    "    \n",
    "    windows = dates.apply(functools.partial(reviews_at_time,group))\n",
    "    #display(windows)\n",
    "    \n",
    "    for idx, window in windows.iterrows():\n",
    "        if len(window.ratings) < 5:\n",
    "            continue\n",
    "        try:\n",
    "            pvalue = scipy.stats.epps_singleton_2samp(window.ratings,all_six_month_windows_binned[window[\"binned_rating\"]])[1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue\n",
    "            \n",
    "        all_windows.append((pvalue,window))\n",
    "        \n",
    "        \n",
    "        yc_updated_reviews_rating.loc[window.indexes][\"windows\"] += 1\n",
    "        \n",
    "        for i in window.indexes:\n",
    "            pvalues[i].append(pvalue)\n",
    "        \n",
    "        if pvalue < 0.01:\n",
    "            yc_updated_reviews_rating.loc[window.indexes][\"atypical_windows\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews_rating.groupby(\"atypical_windows\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "#l1 = []\n",
    "#l2 = []\n",
    "rows = []\n",
    "\n",
    "for k,v in pvalues.items():\n",
    "    windows = len(v)\n",
    "    atypical_windows = len(list(filter(lambda x: x<0.01,v)))\n",
    "    if windows == 0:\n",
    "        continue\n",
    "    index.append(k)\n",
    "    rows.append([windows, atypical_windows, atypical_windows / windows])\n",
    "    #l1.append()\n",
    "    #l2.append()\n",
    "    \n",
    "#Fill with 0s\n",
    "#0 atypical ratio -- assume not atypical if we don't have enough data\n",
    "df = pd.DataFrame(rows,index=index,columns=[\"windows\",\"atypical_windows\",\"atypical_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews_rating[\"atypical_ratio\"] = 0\n",
    "yc_updated_reviews_rating[[\"windows\",\"atypical_windows\",\"atypical_ratio\"]] = df[[\"windows\",\"atypical_windows\",\"atypical_ratio\"]]\n",
    "yc_updated_reviews_rating[[\"windows\",\"atypical_windows\",\"atypical_ratio\"]] = yc_updated_reviews_rating[[\"windows\",\"atypical_windows\",\"atypical_ratio\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(yc_updated_reviews_rating.atypical_ratio, list(map(lambda x: 1 if x else 0, yc_updated_reviews_rating.flagged == \"Y\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews_rating[\"flagged_discrete\"] = yc_updated_reviews_rating.flagged.apply(lambda x: (1 if x==\"Y\" else 0))\n",
    "yc_updated_reviews_rating[\"flagged_perturbed\"] = yc_updated_reviews_rating.flagged_discrete.apply(lambda x: x + random.random() * 0.5 - 0.25)\n",
    "yc_updated_reviews_rating[\"atypical_ratio_perturbed\"] = yc_updated_reviews_rating.atypical_ratio.apply(lambda x: x + random.random() * 0.01 - 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\"atypical_ratio_perturbed\", \"flagged_perturbed\", data=yc_updated_reviews_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(y=\"flagged\", x=\"atypical_ratio\", data=yc_updated_reviews_rating,orient=\"h\",scale=\"width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to do ML on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#366 for leap years\n",
    "twelve_months = pd.Timedelta(\"366 days\")\n",
    "#183 days so that it always includes at least half a year, to account for seasonality\n",
    "six_months = pd.Timedelta(\"183 days\")\n",
    "three_months = pd.Timedelta(\"90 days\")\n",
    "one_month = pd.Timedelta(\"30 days\")\n",
    "half_month = pd.Timedelta(\"15 days\")\n",
    "\n",
    "col_names = [f\"{num}_mo_{rating}_rating_ratio\" for (num,rating) in itertools.product([\"1\",\"2\",\"6\",\"12\"],[\"1\",\"2\",\"3\",\"4\",\"5\"])]\n",
    "business_oh = set\n",
    "\n",
    "def get_rating_distribution(df, date, df_name=\"\"):\n",
    "    \n",
    "    s = pd.Series([0]*len(col_names), index=col_names,name=f\"{df_name} {date}\")\n",
    "    \n",
    "    s[df_name] = 1\n",
    "    s[\"business\"] = df_name\n",
    "    s[\"date\"] = date\n",
    "    \n",
    "    twelve_month_window = df[(df.date < date + six_months) & (df.date >= date - six_months)]\n",
    "    six_month_window = df[(df.date < date + three_months) & (df.date >= date - three_months)]\n",
    "    two_month_window = df[(df.date < date + one_month) & (df.date >= date - one_month)]\n",
    "    one_month_window = df[(df.date < date + half_month) & (df.date >= date - half_month)]\n",
    "    \n",
    "    for window,num in [(twelve_month_window,\"12\"), (six_month_window,\"6\"),(two_month_window,\"2\"),(one_month_window,\"1\")]:\n",
    "        \n",
    "        assert len(window) > 0, f\"{num} {df_name} {date}\"\n",
    "        \n",
    "        s[f\"{num}_mo_filtered_ratio\"] = len(window[window.flagged == \"Y\"]) / len(window)\n",
    "        for rating, count in window.groupby(\"rating\").size().iteritems():\n",
    "            s[f\"{num}_mo_{rating}_rating\"] = count\n",
    "            s[f\"{num}_mo_{rating}_rating_ratio\"] = count / len(window)\n",
    "            \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_filtering_col_names = ([f\"{num}_mo_prior_has_reviews\" for num in [\"1\",\"3\",\"6\",\"12\", \"all\"]] + \n",
    "                             [f\"{num}_mo_prior_filtered_ratio\" for num in [\"1\",\"3\",\"6\",\"12\", \"all\"]] + \n",
    "                             [f\"{num}_mo_prior_review_count\" for num in [\"1\",\"3\",\"6\",\"12\",\"all\"]]\n",
    "                            )  \n",
    "\n",
    "rating_col_names = (\n",
    "    [f\"{num}_mo_prior_has_rec_reviews\" for num in [\"1\",\"3\",\"6\",\"12\", \"all\"]] + \n",
    "    [f\"{num}_mo_prior_rating\" for num in [\"1\",\"3\",\"6\",\"12\", \"all\"]]\n",
    ")\n",
    "\n",
    "def get_prior_filtering(df, date, df_name=\"\"):\n",
    "    \n",
    "    s = pd.Series([0]*len(col_names), index=col_names,name=f\"{df_name} {date}\")\n",
    "    \n",
    "    s[df_name] = 1\n",
    "    s[\"business\"] = df_name\n",
    "    s[\"date\"] = date\n",
    "    \n",
    "#     twelve_months_prior = df[(df.date < date - twelve_months + half_month) & (df.date >= date - twelve_months - half_month)]\n",
    "#     six_months_prior = df[(df.date < date - six_months + half_month) & (df.date >= date - six_months - half_month)]\n",
    "#     three_months_prior = df[(df.date < date - three_months + half_month) & (df.date >= date - three_months - half_month)]\n",
    "#     one_month_prior = df[(df.date < date - one_month + half_month) & (df.date >= date - one_month - half_month)]\n",
    "    \n",
    "    twelve_months_prior = df[(df.date < date - half_month) & (df.date >= date - twelve_months - half_month)]\n",
    "    six_months_prior = df[(df.date < date - half_month) & (df.date >= date - six_months - half_month)]\n",
    "    three_months_prior = df[(df.date < date - half_month) & (df.date >= date - three_months - half_month)]\n",
    "    one_month_prior = df[(df.date < date - half_month) & (df.date >= date - one_month - half_month)]\n",
    "    \n",
    "    one_month_window = df[(df.date < date + half_month) & (df.date >= date - half_month)]\n",
    "    \n",
    "    all_prior = df[df.date < date - half_month]\n",
    "    \n",
    "    s[f\"1_mo_filtered_ratio\"] = len(one_month_window[one_month_window.flagged == \"Y\"]) / len(one_month_window)\n",
    "    s[f\"1_mo_rating\"] = one_month_window[one_month_window.flagged == \"N\"].rating.mean()\n",
    "    \n",
    "    for window,num in [(all_prior,\"all\"),(twelve_months_prior,\"12\"), (six_months_prior,\"6\"),(three_months_prior,\"3\"),(three_months_prior,\"1\")]:\n",
    "        \n",
    "        #assert len(window) > 0\n",
    "        s[f\"{num}_mo_prior_has_reviews\"] = 1 if len(window) > 0 else 0\n",
    "        s[f\"{num}_mo_prior_has_rec_reviews\"] = 1 if len(window[window.flagged == \"N\"]) > 0 else 0\n",
    "        \n",
    "        s[f\"{num}_mo_prior_rating\"] = window[window.flagged == \"N\"].rating.mean() if len(window[window.flagged == \"N\"]) > 0 else 0\n",
    "        \n",
    "        s[f\"{num}_mo_prior_filtered_ratio\"] = len(window[window.flagged == \"Y\"]) / len(window) if len(window) > 0 else 0\n",
    "        s[f\"{num}_mo_prior_review_count\"] = len(window)\n",
    "            \n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(yc_updated_reviews.businessID.unique())\n",
    "\n",
    "all_rating_dfs = []\n",
    "\n",
    "for business_id, group in tqdm(yc_updated_reviews.sample(frac=1).groupby(\"businessID\",sort=False),total=total):\n",
    "    dates = pd.Series(group.date.unique()).sort_values()\n",
    "    \n",
    "    i = 0 #Before\n",
    "    j = 0 #After\n",
    "    \n",
    "    dates_alt = []\n",
    "    \n",
    "    date = dates.min() #datetime.datetime(month=dates.min().month,year=dates.min().year,day=1) + one_month\n",
    "    while date < dates.max():\n",
    "        while i+1 < len(dates) and dates.iloc[i+1] < date:\n",
    "            i += 1\n",
    "        while j+1 < len(dates) and dates.iloc[j+1] > date:\n",
    "            j += 1\n",
    "        \n",
    "        if date - dates.iloc[i] <= half_month or dates.iloc[j] - date < half_month:\n",
    "            dates_alt.append(date)\n",
    "        date += one_month\n",
    "        \n",
    "    dates_alt.append(dates.max())\n",
    "    dates = pd.Series(dates_alt)\n",
    "        \n",
    "    \n",
    "    ratings = dates.apply(functools.partial(get_rating_distribution,group,df_name=business_id))\n",
    "    prior_filtering = dates.apply(functools.partial(get_prior_filtering,group,df_name=business_id))\n",
    "    \n",
    "    df = pd.concat([ratings,prior_filtering],axis=1)\n",
    "    \n",
    "    all_rating_dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rating_dfs_dedup = list(map(lambda df: df.loc[:,~df.columns.duplicated()],all_rating_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.concat(all_rating_dfs_dedup,axis=0).fillna(0)\n",
    "ratings_df = ratings_df.set_index([\"business\", \"date\"],drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df[\"month\"] = ratings_df[\"date\"].map(lambda x: x.month)\n",
    "ratings_df[\"year\"] = ratings_df[\"date\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols = [f\"month_{m}\" for m in ratings_df.month.unique()] + [f\"year_{y}\" for y in ratings_df.year.unique()]\n",
    "for m in ratings_df.month.unique():\n",
    "    ratings_df[f\"month_{m}\"] = ratings_df.month.map(lambda x: 1 if x == m else 0)\n",
    "for y in ratings_df.year.unique():\n",
    "    ratings_df[f\"year_{y}\"] = ratings_df.year.map(lambda x: 1 if x == y else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = KFold(5,shuffle=True)\n",
    "\n",
    "def dfs_to_data(*dfs,columns=None,ret_df=False):\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    if columns is not None:\n",
    "        df = df[columns]\n",
    "    if ret_df:\n",
    "        return df\n",
    "    else:\n",
    "        return df.to_numpy(), list(df)\n",
    "\n",
    "def get_data(*columns,**kwargs):\n",
    "    cols = []\n",
    "    for col_list in columns:\n",
    "        if type(col_list) == str:\n",
    "            cols.append(col_list)\n",
    "        else:\n",
    "            cols += list(col_list)\n",
    "    return dfs_to_data(ratings_df, columns=cols,**kwargs)\n",
    "\n",
    "def linear_regression_statsmodels(y, *columns):\n",
    "    if type(y) == str:\n",
    "        y = business_distances[y]\n",
    "    df =  get_data(*columns, ret_df=True)\n",
    "    df = sm.add_constant(df)\n",
    "    model = sm.OLS(y,df)\n",
    "    results = model.fit()\n",
    "    return results.summary()\n",
    "    \n",
    "def linear_regression_sklearn(y, *columns):\n",
    "    if type(y) == str:\n",
    "        y = ratings_df[y]\n",
    "    X, feature_names =  get_data(*columns)\n",
    "    clf = LinearRegression()\n",
    "    model = clf.fit(X,y)\n",
    "    #scores = cross_val_score(clf, X, y, cv=CV,scoring='neg_mean_squared_error')\n",
    "    scores = cross_val_score(clf, X, y, cv=CV,scoring='r2')\n",
    "    print(f\"Model score: {model.score(X,y)}\\nLOO X-Val: {scores.mean()}\")\n",
    "    return sorted(list(zip(feature_names,model.coef_)), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "def random_forest_regressor_sklearn(y, *columns, **kwargs):\n",
    "    if type(y) == str:\n",
    "        y = ratings_df[y]\n",
    "    X, feature_names = get_data(*columns)\n",
    "    clf = RandomForestRegressor(**kwargs)\n",
    "    model = clf.fit(X,y)\n",
    "    scores = cross_val_score(clf, X, y, cv=CV,scoring='r2')\n",
    "    print(f\"score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(ratings_df)\n",
    "s2 = set(sum([prior_filtering_col_names, list(yc_updated_reviews.businessID.unique()), time_cols],[]))\n",
    "s1 - s2, s2 - s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_regression_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "linear_regression_sklearn(ratings_df[\"1_mo_filtered_ratio\"], prior_filtering_col_names, list(yc_updated_reviews.businessID.unique()), time_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_regression_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "linear_regression_statsmodels(ratings_df[\"1_mo_filtered_ratio\"], prior_filtering_col_names, list(yc_updated_reviews.businessID.unique()), time_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_regression_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "linear_regression_statsmodels(ratings_df[\"1_mo_rating\"], rating_col_names, list(yc_updated_reviews.businessID.unique()), time_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_regression_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "linear_regression_statsmodels(ratings_df[\"1_mo_filtered_ratio\"], prior_filtering_col_names, list(yc_updated_reviews.businessID.unique()), col_names, time_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_regression_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "linear_regression_sklearn(ratings_df[\"1_mo_filtered_ratio\"], col_names, list(yc_updated_reviews.businessID.unique()), time_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest_regressor_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "random_forest_regressor_sklearn(\"1_mo_filtered_ratio\", col_names, prior_filtering_col_names, list(yc_updated_reviews.businessID.unique()), time_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest_regressor_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()))\n",
    "random_forest_regressor_sklearn(\"1_mo_filtered_ratio\", col_names, list(yc_updated_reviews.businessID.unique()), time_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Has the ham distribution changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the rating distrubtion across all businesses static?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews[\"year\"] = yc_updated_reviews.date.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews[\"review_length\"] = yc_updated_reviews.content.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews[yc_updated_reviews.flagged==\"N\"].sort_values(\"year\").groupby(\"year\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    for year, group in yc_updated_reviews[yc_updated_reviews.flagged==\"N\"].sort_values([\"year\",\"rating\"]).groupby([\"year\"]):\n",
    "        print(year)\n",
    "        print(group.groupby(\"rating\").size() / len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = yc_reviews.date.max()\n",
    "old_ratings = yc_reviews[yc_reviews.flagged==\"N\"].groupby(\"businessID\").rating.mean()\n",
    "new_ratings = yc_updated_reviews[(yc_updated_reviews.date <= max_date) & (yc_updated_reviews.flagged==\"N\")].groupby(\"businessID\").rating.mean()\n",
    "\n",
    "rating_diff = new_ratings-old_ratings\n",
    "\n",
    "pd.concat([old_ratings.rename(\"old rating\"),new_ratings.rename(\"new rating\"),rating_diff.rename(\"diff\")],axis=1).sort_values(\"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bid in yc_reviews.businessID.unique():\n",
    "    try:\n",
    "        if yc_businesses.loc[bid] is not None:\n",
    "            continue\n",
    "    except KeyError:\n",
    "        pass\n",
    "    print(bid)\n",
    "    assert len(yc_businesses[yc_businesses.id == bid].name) == 1, bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_businesses.loc[\"g51qDl6fQhgat-kFTrcbug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews[\"matchFlagged\"] = yc_reviews.matchID.map(lambda x: yc_updated_reviews.loc[x].flagged, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews[\"year\"] = yc_reviews.date.map(lambda x: x.year)\n",
    "yc_reviews[\"month\"] = yc_reviews.date.map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews[\"matchFlagged\"] = yc_reviews[\"matchFlagged\"].fillna(\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "labels = []\n",
    "for (startFlag,endFlag), group in yc_reviews.groupby([\"flagged\",\"matchFlagged\"]):\n",
    "    labels.append(\",\".join([startFlag,endFlag]))\n",
    "    rows.append(group.groupby(\"year\").size() / yc_reviews.groupby(\"year\").size())\n",
    "    \n",
    "pd.DataFrame(rows,index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews.groupby(\"year\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "indexes = []\n",
    "for (flag,mflag), group in yc_reviews.groupby([\"flagged\", \"matchFlagged\"]):\n",
    "    rows.append(group.groupby(\"year\").size())\n",
    "    indexes.append(f\"{flag}->{mflag}\")\n",
    "    \n",
    "display(\"Number in each category by year\")\n",
    "pd.DataFrame(rows,index=indexes,dtype=\"int64\").fillna(0).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "indexes = []\n",
    "for (flag,mflag), group in yc_reviews.groupby([\"flagged\", \"matchFlagged\"]):\n",
    "    s = pd.Series(index=sorted(yc_reviews.year.unique()),dtype=\"object\")\n",
    "    for year, ygroup in group.groupby(\"year\"):\n",
    "        months = ygroup.groupby(\"month\").size()\n",
    "        s[year] = f\"{months.max()}/{months.min()}\"\n",
    "    rows.append(s)\n",
    "    indexes.append(f\"{flag}->{mflag}\")\n",
    "\n",
    "print(\"Min/Max month by year\")\n",
    "pd.DataFrame(rows,index=indexes).fillna(\"0/0\")2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "indexes = []\n",
    "for (flag,mflag), group in yc_reviews.groupby([\"flagged\", \"matchFlagged\"]):\n",
    "    rows.append(group.groupby(\"year\").size())\n",
    "    indexes.append(f\"{flag}->{mflag}\")\n",
    "    \n",
    "pd.DataFrame(rows,index=indexes,dtype=\"int64\").fillna(0).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "labels = []\n",
    "for (startFlag,endFlag), group in yc_reviews.groupby([\"flagged\",\"matchFlagged\"]):\n",
    "    labels.append(\",\".join([startFlag,endFlag]))\n",
    "    rows.append(group.groupby(\"year\").size() / yc_reviews[yc_reviews.flagged == startFlag].groupby(\"year\").size())\n",
    "    \n",
    "pd.DataFrame(rows,index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(yc_updated_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(yc_businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = {\n",
    "    yc_id: row.id\n",
    "    for yc_id, row in yc_businesses.loc[yc_updated_reviews.businessID.unique()].iterrows()\n",
    "}\n",
    "yc_updated_reviews[\"businessID_yc\"] = yc_updated_reviews.businessID.map(id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([yc_reviews[yc_reviews.flagged==\"N\"].groupby(\"businessID\").rating.mean().rename(\"old_rating\"), yc_updated_reviews[(yc_updated_reviews.date <= yc_reviews.date.max()) & (yc_updated_reviews.flagged==\"N\")].groupby(\"businessID\").rating.mean().rename(\"new_rating\")],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = df.new_rating - df.old_rating\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[df.new_rating.isnull()])\n",
    "display(df[df.old_rating.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_updated_reviews[yc_updated_reviews.businessID == \"BISUDalmPulSzHvsO3PhDA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_reviews[yc_reviews.businessID == \"BISUDalmPulSzHvsO3PhDA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
