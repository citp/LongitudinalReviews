{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import pandas  as pd\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import datetime\n",
    "import math\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to run this\n",
    "if False:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = True\n",
    "constants.set_crawl_source(constants.CRAWL_SOURCE_EXTENDED if extended else constants.CRAWL_SOURCE_CHICAGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crawl = \"crawl_x3\" if extended else \"crawl_17\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(constants.ZIPCODE_TO_STRATA, \"rb+\") as fp:\n",
    "    zc_to_strata = pickle.load(fp)\n",
    "\n",
    "zipcodes = constants.EXTENDED_ZIPCODES\n",
    "\n",
    "with open(constants.CENSUS_STRATA_DATA, \"rb+\") as fp:\n",
    "    df_strata = pd.read_pickle(fp)\n",
    "    df_strata = df_strata.loc[zipcodes]\n",
    "    \n",
    "business_df = pd.read_pickle(constants.BUSINESS_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(constants.LONG_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_business_data = pd.read_pickle(constants.CRAWLED_BUSINESS_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a = set(crawled_business_data.business_id)\n",
    "set_b = set(df[df.crawl_id == target_crawl].business_id)\n",
    "print(f\"{len(set_a)}, {len(set_b)}, {len(set_a & set_b)}, {len(set_a | set_b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ammenity in tqdm([\"num_ammenities\",\"ammenity_customers_must_wear_masks\",\"ammenity_employees_wear_masks\",\"ammenity_restaurants_attire\",\"ammenity_Caters\",\"ammenity_dogs_allowed\",\"ammenity_employees_wear_masks\"]):\n",
    "    if ammenity not in df:\n",
    "        df[ammenity] = df[df.crawl_id == target_crawl].apply(lambda row: crawled_business_data[ammenity].loc[(target_crawl,row.business_id)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df[df.crawl_id == target_crawl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_words = [\"mask\",\"vaccine\"]\n",
    "flagged_lemmas = set((lemmatizer.lemmatize(word) for word in flagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gaurav5430.medium.com/using-nltk-for-lemmatizing-sentences-c1bfff963258\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def get_word_flags(review):\n",
    "    flags = {f\"flag_{fl}\": False for fl in flagged_lemmas}\n",
    "    for token, tag in nltk.pos_tag(nltk.word_tokenize(review)):\n",
    "        tag = nltk_tag_to_wordnet_tag(tag)\n",
    "        if tag is None:\n",
    "            tag = \"n\"\n",
    "        lemma = lemmatizer.lemmatize(token, pos=tag)\n",
    "        if lemma in flagged_lemmas:\n",
    "            flags[f\"flag_{lemma}\"] = True\n",
    "    return pd.Series(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flagged = pd.concat([df_target, df_target.content.progress_apply(get_word_flags)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_flagged[df_flagged.crawl_id == target_crawl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at ammenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportion_matching(subdf,parent_df=None,ammenity=None):\n",
    "#     ammenity_value = subdf[ammenity].iloc[0]\n",
    "#     experiments = subdf.experiment.unique()\n",
    "#     all_with_params = parent_df[(parent_df.experiment.isin(experiments)) & (parent_df[ammenity].isna() if math.isnan(ammenity_value) else (parent_df[ammenity] == ammenity_value))]\n",
    "\n",
    "    try:\n",
    "        ammenity_value = subdf[ammenity].iloc[0]\n",
    "    except KeyError:\n",
    "        ammenity_value = parent_df.loc[subdf.index][ammenity].iloc[0]\n",
    "    experiments = subdf.experiment.unique()\n",
    "    all_with_params = parent_df[(parent_df.experiment.isin(experiments)) & (parent_df[ammenity].isna() if (type(ammenity_value) == float and math.isnan(ammenity_value)) else (parent_df[ammenity] == ammenity_value))]\n",
    "\n",
    "    return len(subdf)/len(all_with_params)\n",
    "\n",
    "def fill_proportion_matching(subdf,parent_df=None,ammenity=None):\n",
    "    try:\n",
    "        ammenity_value = subdf[ammenity].iloc[0]\n",
    "    except KeyError:\n",
    "        ammenity_value = parent_df.loc[subdf.index][ammenity].iloc[0]\n",
    "    experiments = subdf.experiment.unique()\n",
    "    all_with_params = parent_df[(parent_df.experiment.isin(experiments)) & (parent_df[ammenity].isna() if (type(ammenity_value) == float and math.isnan(ammenity_value)) else (parent_df[ammenity] == ammenity_value))]\n",
    "    return pd.Series([1] * len(subdf) + [0] * (len(all_with_params) - len(subdf)))\n",
    "\n",
    "def get_significance(subdf,parent_df=None,base_trait=None,ammenity=None):\n",
    "    ks_stat,ks_p_value =scipy.stats.ks_2samp(subdf[base_trait], parent_df[base_trait])\n",
    "    es_stat,es_p_value =scipy.stats.epps_singleton_2samp(subdf[base_trait], parent_df[base_trait])\n",
    "    return pd.Series([ks_stat, ks_p_value, es_stat, es_p_value, len(subdf)], index=[\"ks_stat\",\"ks_p_value\",\"es_stat\",\"es_p_value\",\"size\"])\n",
    "\n",
    "def plot_ammenity_rating(subdf, ammenity, parent_df=None, base_trait=\"rating\",suffix=\"\",plot_kwargs={}):\n",
    "    \n",
    "    if parent_df is None:\n",
    "        parent_df = subdf\n",
    "        \n",
    "    if len(suffix) != 0 and suffix[0] != \"_\":\n",
    "        suffix = f\"_{suffix}\"\n",
    "    \n",
    "    try:\n",
    "        display(subdf.groupby([ammenity], dropna=False).apply(get_significance, parent_df=parent_df,ammenity=ammenity,base_trait=base_trait))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f\"Correlation: {scipy.stats.spearmanr(df_target[base_trait], df_target[ammenity])}\")\n",
    "    except:\n",
    "        print(\"Unable to perform correlation check\")\n",
    "    try:\n",
    "        df_rating_masked  = subdf.groupby([ammenity,base_trait], dropna=False).apply(fill_proportion_matching, parent_df=parent_df, ammenity=ammenity).reset_index()\n",
    "    except KeyError:\n",
    "        print(list(subdf))\n",
    "        raise\n",
    "    df_rating_masked_filled = df_rating_masked.fillna(\"Not listed\")\n",
    "    sns.barplot(x=base_trait,y=0,hue=ammenity,data=df_rating_masked_filled,**plot_kwargs).set(xlabel=\"Rating\",ylabel=\"Proportion\")#.set(title=f\"Proprotion of reviews with each {base_trait}\")\n",
    "    fn = f\"proprotion_{ammenity}_by_{base_trait}_{constants.CRAWL_SOURCE}{suffix}.pdf\".replace(\"/\",\"_\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.savefig(f\"../../graphs/{fn}\", bbox_inches = 'tight')\n",
    "    print(f\"Saved to ../../graphs/{fn}\")\n",
    "#     df_rating_masked  = subdf.groupby([ammenity,base_trait], dropna=False).apply(get_proportion_matching, parent_df=parent_df, ammenity=ammenity).reset_index()\n",
    "#     df_rating_masked_filled = df_rating_masked.fillna(\"Not listed\")\n",
    "#     sns.barplot(x=base_trait,y=0,hue=ammenity,data=df_rating_masked_filled).set(title=f\"Proprotion of reviews with each {base_trait}\")\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Stats:\n",
    "Mask mentions:\n",
    "{df_target[(df_target.date >= pd.to_datetime(\"2020-03-01\"))].flag_mask.value_counts()}\n",
    "Mask requirements by business:\n",
    "{crawled_business_data['ammenity_customers_must_wear_masks'].value_counts(dropna=False)}\n",
    "Mask requirements by review:\n",
    "{df_target[df_target.date >= pd.to_datetime(\"2020-08-06\")]['ammenity_customers_must_wear_masks'].value_counts(dropna=False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(df_target.rating, df_target.num_ammenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.groupby([\"experiment\",\"stratum\"]).apply(lambda subdf: pd.Series(list(scipy.stats.spearmanr(subdf.rating, subdf.num_ammenities)),index=[\"correlation\",\"p_value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target, \"num_ammenities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target, \"ammenity_restaurants_attire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target, \"ammenity_Caters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target, \"ammenity_dogs_allowed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target, \"ammenity_employees_wear_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target, \"ammenity_customers_must_wear_masks\", base_trait=\"flagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target[df_target.date >= pd.to_datetime(\"2021-08-01\")], \"ammenity_customers_must_wear_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target['ammenity_customers_must_wear_masks'] = df_target['ammenity_customers_must_wear_masks'].fillna(\"Not listed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scipy.stats.ks_2samp(df_target[df_target.ammenity_customers_must_wear_masks == \"Not listed\"].rating, df_target[df_target.ammenity_customers_must_wear_masks != \"Not listed\"].rating))\n",
    "display(scipy.stats.ks_2samp(df_target[df_target.ammenity_customers_must_wear_masks == True].rating, df_target[df_target.ammenity_customers_must_wear_masks == False].rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target[(df_target.flag_mask) & (df_target.date >= pd.to_datetime(\"2021-07-01\"))], \"ammenity_customers_must_wear_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reviews that mention masks\")\n",
    "df_target[\"Masks mentions/masks required\"] = df_target.apply(lambda row: f\"{row['flag_mask']}/{row['ammenity_customers_must_wear_masks']}\",axis=1)\n",
    "df_march_2020 = df_target[df_target.date >= pd.to_datetime(\"2021-07-06\")].copy()\n",
    "plot_ammenity_rating(df_march_2020, \"Masks mentions/masks required\")\n",
    "# subdf = df_march_2020\n",
    "# parent_df = subdf\n",
    "# base_trait = \"rating\"\n",
    "# ammenity = \"masks_mentioned_masks_required\"\n",
    "# try:\n",
    "#     df_rating_masked  = subdf.groupby([ammenity,base_trait]).apply(fill_proportion_matching, parent_df=parent_df, ammenity=ammenity).reset_index()\n",
    "# except KeyError:\n",
    "#     print(list(subdf))\n",
    "#     raise\n",
    "# df_rating_masked_filled = df_rating_masked.fillna(\"Not listed\")\n",
    "# sns.barplot(x=base_trait,y=0,hue=ammenity,data=df_rating_masked_filled).set(title=f\"Proprotion of reviews with each {base_trait}\")\n",
    "df_march_2020 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reviews that mention masks\")\n",
    "df_target['ammenity_customers_must_wear_masks'] = df_target['ammenity_customers_must_wear_masks'].fillna(\"Not listed\")\n",
    "df_march_2020 = df_target[df_target.date >= pd.to_datetime(\"2020-03-01\")].copy()\n",
    "df_august_2021 = df_target[df_target.date >= pd.to_datetime(\"2021-08-06\")].copy()\n",
    "index=[\"flagged\", \"Masks:\",\"Rating\"]\n",
    "results_df1 = df_march_2020.apply(lambda row: pd.Series([row.flagged,\"Mentioned\" if row['flag_mask'] else \"Not mentioned\", row.rating],index=index),axis=1)\n",
    "results_df2 = df_august_2021.apply(lambda row: pd.Series([row.flagged,\"Required\" if row['ammenity_customers_must_wear_masks'] == True else (\"Not required\" if row['ammenity_customers_must_wear_masks'] == False else row['ammenity_customers_must_wear_masks']), row.rating],index=index),axis=1)\n",
    "results_df = pd.concat([results_df1,results_df2])\n",
    "results_df[\"experiment\"] = -1\n",
    "\n",
    "plot_kwargs = {\"hue_order\":[\"Required\",\"Not required\", \"Not listed\", \"Mentioned\", \"Not mentioned\"]}\n",
    "\n",
    "plot_ammenity_rating(results_df, ammenity=\"Masks:\",base_trait=\"Rating\",plot_kwargs=plot_kwargs)\n",
    "plt.show()\n",
    "plot_ammenity_rating(results_df[results_df.flagged == False], ammenity=\"Masks:\",base_trait=\"Rating\",plot_kwargs=plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recommended\")\n",
    "display(scipy.stats.spearmanr(df_august_2021[(df_august_2021.flagged == False) & (df_august_2021.ammenity_customers_must_wear_masks != \"Not listed\")].ammenity_customers_must_wear_masks, df_august_2021[(df_august_2021.flagged == False) & (df_august_2021.ammenity_customers_must_wear_masks != \"Not listed\")].rating))\n",
    "display(results_df[(results_df.flagged == False)].groupby(\"Masks:\").mean())\n",
    "display(results_df[(results_df.flagged == False)].groupby(\"Masks:\").std())\n",
    "print(\"All\")\n",
    "display(scipy.stats.spearmanr(df_august_2021[(df_august_2021.ammenity_customers_must_wear_masks != \"Not listed\")].ammenity_customers_must_wear_masks, df_august_2021[(df_august_2021.ammenity_customers_must_wear_masks != \"Not listed\")].rating))\n",
    "display(results_df.groupby(\"Masks:\").mean())\n",
    "display(results_df.groupby(\"Masks:\").std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df1 = None\n",
    "results_df2 = None\n",
    "results_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reviews that mention masks\")\n",
    "df_target['ammenity_customers_must_wear_masks'] = df_target['ammenity_customers_must_wear_masks'].fillna(\"Not listed\")\n",
    "df_target[\"Masks mentions/masks required\"] = df_target.apply(lambda row: f\"{row['flag_mask']}/{row['ammenity_customers_must_wear_masks']}\",axis=1)\n",
    "df_march_2020 = df_target[df_target.date >= pd.to_datetime(\"2021-08-06\")].copy()\n",
    "plot_ammenity_rating(df_march_2020, \"Masks mentions/masks required\")\n",
    "# subdf = df_march_2020\n",
    "# parent_df = subdf\n",
    "# base_trait = \"rating\"\n",
    "# ammenity = \"masks_mentioned_masks_required\"\n",
    "# try:\n",
    "#     df_rating_masked  = subdf.groupby([ammenity,base_trait]).apply(fill_proportion_matching, parent_df=parent_df, ammenity=ammenity).reset_index()\n",
    "# except KeyError:\n",
    "#     print(list(subdf))\n",
    "#     raise\n",
    "# df_rating_masked_filled = df_rating_masked.fillna(\"Not listed\")\n",
    "# sns.barplot(x=base_trait,y=0,hue=ammenity,data=df_rating_masked_filled).set(title=f\"Proprotion of reviews with each {base_trait}\")\n",
    "df_march_2020 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ammenity_rating(df_target[~df_target.flag_mask], \"ammenity_customers_must_wear_masks\", parent_df=df_target, suffix=\"not_mentions_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage of reviews that mention masks that occur before March 01, 2021 {len(df_flagged[df_flagged.flag_mask & (df_flagged.date < pd.to_datetime(\"2020-03-01\"))]) / len(df_flagged[df_flagged.flag_mask]):%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(x=\"date\",data=df_flagged[df_flagged.flag_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flagged[df_flagged.flag_mask & (df_flagged.date >= pd.to_datetime(\"2020-03-01\"))].sample(1).content.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month = pd.Timedelta(\"30 days\")\n",
    "three_months = pd.Timedelta(\"90 days\")\n",
    "\n",
    "def get_windowed_view(df,field,start_time=None):\n",
    "    if start_time is None:\n",
    "        start_time = datetime.datetime(year=df.date.min().year,month=1,day=1)\n",
    "    end_time = datetime.datetime(year=df.date.max().year+1,month=1,day=1)\n",
    "    for stratum in df_flagged_crawl.stratum.unique():\n",
    "        df_s = df[df.stratum == stratum]\n",
    "        t = start_time\n",
    "        while t < end_time:\n",
    "            t += one_month\n",
    "            for business_id, subdf in df_s.groupby(\"business_id\"):\n",
    "                prop = windowed_proportion(subdf,t,field)\n",
    "                if prop != None:\n",
    "                    yield pd.Series({\"business_id\": business_id, \"stratum\": stratum, \"date\": t, \"proportion\": prop})\n",
    "\n",
    "def windowed_proportion(df,date,field):\n",
    "    df_window = df[(df.date < date) & (df.date >= date - one_month)]\n",
    "    if len(df_window) == 0:\n",
    "        return None\n",
    "    return len(df_window[df_window[field]])/len(df_window)\n",
    "\n",
    "for experiment, experiment_name in [(2,\"Density\"),(3,\"Income\")]:\n",
    "    for crawl_id in constants.CRAWL_ORDER[-1:]:\n",
    "        df_flagged_crawl = df_flagged[(df_flagged.experiment == experiment) & (df_flagged.crawl_id == crawl_id)]\n",
    "        data = pd.DataFrame(get_windowed_view(df_flagged_crawl,\"flag_mask\",start_time=datetime.datetime(year=2020,month=1,day=1)))\n",
    "        sns.lineplot(x=\"date\",y=\"proportion\",hue=\"stratum\",palette=\"tab10\",data=data).set(title=f\"Proportion of reviews that mention mask, 1 month sliding window ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month = pd.Timedelta(\"30 days\")\n",
    "three_months = pd.Timedelta(\"90 days\")\n",
    "\n",
    "def get_windowed_view(df,field):\n",
    "    start_time = datetime.datetime(year=2020,month=1,day=1)\n",
    "    end_time = datetime.datetime(year=df.date.max().year+1,month=1,day=1)\n",
    "    for stratum in df_flagged_crawl.stratum.unique():\n",
    "        df_s = df[df.stratum == stratum]\n",
    "        t = start_time\n",
    "        while t < end_time:\n",
    "            t += one_month\n",
    "            prop = windowed_proportion(df_s,t,field)\n",
    "            if prop != None:\n",
    "                yield pd.Series({\"stratum\": stratum, \"date\": t, \"proportion\": prop})\n",
    "\n",
    "def windowed_proportion(df,date,field):\n",
    "    df_window = df[(df.date < date + one_month) & (df.date >= date - one_month)]\n",
    "    if len(df_window) == 0:\n",
    "        return None\n",
    "    return len(df_window[df_window[field]])/len(df_window)\n",
    "\n",
    "for experiment, experiment_name in [(2,\"Density\"),(3,\"Income\")]:\n",
    "    for crawl_id in constants.CRAWL_ORDER[-1:]:\n",
    "        df_flagged_crawl = df_flagged[(df_flagged.experiment == experiment) & (df_flagged.crawl_id == crawl_id) & (df_flagged.flag_mask)]\n",
    "        data = pd.DataFrame(get_windowed_view(df_flagged_crawl,\"flagged\"))\n",
    "        ax = sns.lineplot(x=\"date\",y=\"proportion\",hue=\"stratum\",palette=\"tab10\",data=data)\n",
    "        ax.set(title=f\"Proportion of reviews that mention mask that were not recommended, 2 month sliding window ({experiment_name}/{crawl_id})\")\n",
    "        for item in ax.get_xticklabels():\n",
    "            item.set_rotation(45)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month = pd.Timedelta(\"30 days\")\n",
    "three_months = pd.Timedelta(\"90 days\")\n",
    "\n",
    "def get_windowed_view(df,field):\n",
    "    start_time = datetime.datetime(year=df.date.min().year,month=1,day=1)\n",
    "    end_time = datetime.datetime(year=df.date.max().year+1,month=1,day=1)\n",
    "    for stratum in df_flagged_crawl.stratum.unique():\n",
    "        df_s = df[df.stratum == stratum]\n",
    "        t = start_time\n",
    "        while t < end_time:\n",
    "            t += one_month\n",
    "            prop = windowed_proportion(df_s,t,field)\n",
    "            if prop != None:\n",
    "                yield pd.Series({\"stratum\": stratum, \"date\": t, \"proportion\": prop})\n",
    "\n",
    "def windowed_proportion(df,date,field):\n",
    "    df_window = df[(df.date < date + three_months) & (df.date >= date - three_months)]\n",
    "    if len(df_window) == 0:\n",
    "        return None\n",
    "    return len(df_window[df_window[field]])/len(df_window)\n",
    "\n",
    "for experiment, experiment_name in [(2,\"Density\"),(3,\"Income\")]:\n",
    "    for crawl_id in constants.CRAWL_ORDER[-1:]:\n",
    "        df_flagged_crawl = df_flagged[(df_flagged.experiment == experiment) & (df_flagged.crawl_id == crawl_id)]\n",
    "        data = pd.DataFrame(get_windowed_view(df_flagged_crawl,\"flagged\"))\n",
    "        sns.lineplot(x=\"date\",y=\"proportion\",hue=\"stratum\",palette=\"tab10\",data=data).set(title=f\"Proportion of reviews that were not recommended, 6 month sliding window ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment, experiment_name in [(2,\"Density\"),(3,\"Income\")]:\n",
    "    for crawl_id in constants.CRAWL_ORDER[-1:]:\n",
    "        df_flagged_crawl = df_flagged[(df_flagged.experiment == experiment) & (df_flagged.crawl_id == crawl_id)]\n",
    "        sns.ecdfplot(x=\"date\",hue=\"stratum\",data=df_flagged_crawl[df_flagged_crawl.flag_mask & df_flagged_crawl.flagged],stat=\"count\").set(title=f\"Number of not recommended reviews mentioning masks ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()\n",
    "        sns.ecdfplot(x=\"date\",hue=\"stratum\",data=df_flagged_crawl[df_flagged_crawl.flag_mask],stat=\"count\").set(title=f\"Number of reviews mentioning masks ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment, experiment_name in [(2,\"Density\"),(3,\"Income\")]:\n",
    "    for crawl_id in constants.CRAWL_ORDER[-1:]:\n",
    "        df_flagged_crawl = df_flagged[(df_flagged.experiment == experiment) & (df_flagged.crawl_id == crawl_id)]\n",
    "        sns.ecdfplot(x=\"date\",hue=\"stratum\",data=df_flagged_crawl[df_flagged_crawl.flag_mask],stat=\"count\").set(title=f\"Number of reviews mentioning masks ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()\n",
    "        sns.ecdfplot(x=\"date\",hue=\"stratum\",data=df_flagged_crawl,stat=\"count\").set(title=f\"All reviews ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All proportions normalized by stratum\")\n",
    "\n",
    "for experiment, experiment_name in [(2,\"Density\"),(3,\"Income\")]:\n",
    "    for crawl_id in constants.CRAWL_ORDER:\n",
    "        \n",
    "        df_flagged_crawl = df_flagged[df_flagged.crawl_id == crawl_id]\n",
    "\n",
    "        flagged_counts = df_flagged_crawl[df_flagged_crawl.experiment==experiment].groupby([\"flag_mask\",\"stratum\"]).size()\n",
    "        print(f\"{experiment_name} strata sizes\")\n",
    "        display(flagged_counts)\n",
    "        def relative_size(subdf):\n",
    "            if len(subdf) == 0:\n",
    "                return None\n",
    "            return len(subdf)/flagged_counts.loc[(subdf.flag_mask.iloc[0],subdf.stratum.iloc[0])]\n",
    "\n",
    "        heatmap_data = df_flagged_crawl[df_flagged_crawl.experiment==experiment].groupby([\"stratum\",\"flag_mask\",\"rating\"]).apply(relative_size).rename(\"count\").to_frame().reset_index().dropna()\n",
    "        heatmap_data_flagged = heatmap_data[heatmap_data.flag_mask].pivot(\"stratum\",\"rating\",\"count\")\n",
    "        sns.heatmap(data=heatmap_data_flagged).set(title=f\"Proportion of reviews mentioning masks with a rating in each strata ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()\n",
    "\n",
    "        flagged_counts = df_flagged_crawl[df_flagged_crawl.experiment==experiment].groupby([\"stratum\"]).size()\n",
    "        def relative_size(subdf):\n",
    "            if len(subdf) == 0:\n",
    "                return None\n",
    "            return len(subdf)/flagged_counts.loc[subdf.stratum.iloc[0]]\n",
    "\n",
    "        heatmap_data = df_flagged_crawl[df_flagged_crawl.experiment==experiment].groupby([\"stratum\",\"rating\"]).apply(relative_size).rename(\"count\").to_frame().reset_index().dropna()\n",
    "        heatmap_data_no_flag = heatmap_data.pivot(\"stratum\",\"rating\",\"count\")\n",
    "        sns.heatmap(data=heatmap_data_no_flag,vmin=0,vmax=1).set(title=f\"Proportion of reviews with a rating in each strata ({experiment_name}/{crawl_id})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_counts = df_flagged.flag_mask.value_counts()\n",
    "def relative_size(subdf):\n",
    "    if len(subdf) == 0:\n",
    "        return None\n",
    "    return len(subdf)/flagged_counts.loc[subdf.flag_mask.iloc[0]]\n",
    "\n",
    "heatmap_data = df_flagged[df_flagged.experiment==2].groupby([\"stratum\",\"flag_mask\",\"flagged\"]).size().rename(\"count\").to_frame().reset_index().dropna()\n",
    "heatmap_data_flagged = heatmap_data[heatmap_data.flag_mask].pivot(\"stratum\",\"flagged\",\"count\")\n",
    "sns.heatmap(data=heatmap_data_flagged)\n",
    "plt.show()\n",
    "heatmap_data_no_flag = heatmap_data[~heatmap_data.flag_mask].pivot(\"stratum\",\"flagged\",\"count\")\n",
    "sns.heatmap(data=heatmap_data_no_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
